batch_size: 128
epochs: 50
bce_loss: True
unscale_lr: True
rec: False
freeze: True
model: jigsaw_small_patch56_336
input_size: 336
permcls: 1000
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-08
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000/best_checkpoint.pth
attn_only: False
data_path: /workspace/data/imagenet/ILSVRC/Data/CLS-LOC
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000frcl50
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 8
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

batch_size: 128
epochs: 50
bce_loss: True
unscale_lr: True
rec: False
freeze: True
model: jigsaw_small_patch56_336
input_size: 336
permcls: 1000
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-08
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000/best_checkpoint.pth
attn_only: False
data_path: /workspace/data/imagenet/ILSVRC/Data/CLS-LOC
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000frcl50
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 8
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

{"train_lr": 0.001, "train_loss_total": 4.1624045968055725, "train_loss_cls": 4.1624045968055725, "train_acc1_cls": 7.12890625, "train_acc5_cls": 19.482421875, "epoch": 0, "n_parameters": 319077484}
{"train_lr": 0.001, "train_loss_total": 3.749649703502655, "train_loss_cls": 3.749649703502655, "train_acc1_cls": 17.919921875, "train_acc5_cls": 33.544921875, "epoch": 1, "n_parameters": 319077484}
{"train_lr": 0.0009990133740804938, "train_loss_total": 3.5233687460422516, "train_loss_cls": 3.5233687460422516, "train_acc1_cls": 25.09765625, "train_acc5_cls": 41.162109375, "epoch": 2, "n_parameters": 319077484}
{"train_lr": 0.0009960573900837325, "train_loss_total": 3.335532784461975, "train_loss_cls": 3.335532784461975, "train_acc1_cls": 29.248046875, "train_acc5_cls": 44.82421875, "epoch": 3, "n_parameters": 319077484}
{"train_lr": 0.0009911437139280908, "train_loss_total": 3.043270170688629, "train_loss_cls": 3.043270170688629, "train_acc1_cls": 33.642578125, "train_acc5_cls": 53.466796875, "epoch": 4, "n_parameters": 319077484}
{"train_lr": 0.00098429173764851, "train_loss_total": 2.9578908681869507, "train_loss_cls": 2.9578908681869507, "train_acc1_cls": 37.79296875, "train_acc5_cls": 55.615234375, "epoch": 5, "n_parameters": 319077484}
{"train_lr": 0.0009755285028649953, "train_loss_total": 2.8678457736968994, "train_loss_cls": 2.8678457736968994, "train_acc1_cls": 43.505859375, "train_acc5_cls": 57.861328125, "epoch": 6, "n_parameters": 319077484}
{"train_lr": 0.0009648885940616963, "train_loss_total": 2.678178369998932, "train_loss_cls": 2.678178369998932, "train_acc1_cls": 44.82421875, "train_acc5_cls": 61.669921875, "epoch": 7, "n_parameters": 319077484}
{"train_lr": 0.0009524140020977476, "train_loss_total": 2.4298600256443024, "train_loss_cls": 2.4298600256443024, "train_acc1_cls": 51.26953125, "train_acc5_cls": 71.2890625, "epoch": 8, "n_parameters": 319077484}
{"train_lr": 0.0009381539584885315, "train_loss_total": 2.232478618621826, "train_loss_cls": 2.232478618621826, "train_acc1_cls": 56.787109375, "train_acc5_cls": 74.853515625, "epoch": 9, "n_parameters": 319077484}
{"train_lr": 0.0009221647411113801, "train_loss_total": 2.0616914331912994, "train_loss_cls": 2.0616914331912994, "train_acc1_cls": 62.98828125, "train_acc5_cls": 78.90625, "epoch": 10, "n_parameters": 319077484}
{"train_lr": 0.0009045094521025019, "train_loss_total": 2.0295837968587875, "train_loss_cls": 2.0295837968587875, "train_acc1_cls": 63.76953125, "train_acc5_cls": 78.7109375, "epoch": 11, "n_parameters": 319077484}
{"train_lr": 0.000885257768821681, "train_loss_total": 1.7997103035449982, "train_loss_cls": 1.7997103035449982, "train_acc1_cls": 69.921875, "train_acc5_cls": 83.3984375, "epoch": 12, "n_parameters": 319077484}
{"train_lr": 0.0008644856688675688, "train_loss_total": 1.7682114839553833, "train_loss_cls": 1.7682114839553833, "train_acc1_cls": 71.337890625, "train_acc5_cls": 83.69140625, "epoch": 13, "n_parameters": 319077484}
{"train_lr": 0.0008422751302288148, "train_loss_total": 1.746853344142437, "train_loss_cls": 1.746853344142437, "train_acc1_cls": 70.3125, "train_acc5_cls": 84.033203125, "epoch": 14, "n_parameters": 319077484}
{"train_lr": 0.0008187138077543961, "train_loss_total": 1.5511332154273987, "train_loss_cls": 1.5511332154273987, "train_acc1_cls": 75.390625, "train_acc5_cls": 87.59765625, "epoch": 15, "n_parameters": 319077484}
{"train_lr": 0.0007938946872199753, "train_loss_total": 1.5603926107287407, "train_loss_cls": 1.5603926107287407, "train_acc1_cls": 74.70703125, "train_acc5_cls": 88.134765625, "epoch": 16, "n_parameters": 319077484}
{"train_lr": 0.0007679157183555235, "train_loss_total": 1.3585885167121887, "train_loss_cls": 1.3585885167121887, "train_acc1_cls": 80.56640625, "train_acc5_cls": 92.236328125, "epoch": 17, "n_parameters": 319077484}
{"train_lr": 0.0007408794282824873, "train_loss_total": 1.2917451933026314, "train_loss_cls": 1.2917451933026314, "train_acc1_cls": 82.71484375, "train_acc5_cls": 90.91796875, "epoch": 18, "n_parameters": 319077484}
{"train_lr": 0.0007128925168860787, "train_loss_total": 1.1993716284632683, "train_loss_cls": 1.1993716284632683, "train_acc1_cls": 83.88671875, "train_acc5_cls": 92.822265625, "epoch": 19, "n_parameters": 319077484}
{"train_lr": 0.0006840654357195758, "train_loss_total": 1.1505347192287445, "train_loss_cls": 1.1505347192287445, "train_acc1_cls": 85.302734375, "train_acc5_cls": 94.287109375, "epoch": 20, "n_parameters": 319077484}
{"train_lr": 0.000654511952102502, "train_loss_total": 1.0824786499142647, "train_loss_cls": 1.0824786499142647, "train_acc1_cls": 86.81640625, "train_acc5_cls": 94.287109375, "epoch": 21, "n_parameters": 319077484}
{"train_lr": 0.0006243487001329917, "train_loss_total": 1.0123647563159466, "train_loss_cls": 1.0123647563159466, "train_acc1_cls": 88.76953125, "train_acc5_cls": 95.80078125, "epoch": 22, "n_parameters": 319077484}
{"train_lr": 0.0005936947203862894, "train_loss_total": 0.9502422623336315, "train_loss_cls": 0.9502422623336315, "train_acc1_cls": 89.94140625, "train_acc5_cls": 96.19140625, "epoch": 23, "n_parameters": 319077484}
{"train_lr": 0.0005626709901159845, "train_loss_total": 0.9446004331111908, "train_loss_cls": 0.9446004331111908, "train_acc1_cls": 89.111328125, "train_acc5_cls": 96.58203125, "epoch": 24, "n_parameters": 319077484}
{"train_lr": 0.0005313999458120591, "train_loss_total": 0.9095162749290466, "train_loss_cls": 0.9095162749290466, "train_acc1_cls": 90.771484375, "train_acc5_cls": 96.728515625, "epoch": 25, "n_parameters": 319077484}
{"train_lr": 0.0005000050000000001, "train_loss_total": 0.8662728369235992, "train_loss_cls": 0.8662728369235992, "train_acc1_cls": 90.72265625, "train_acc5_cls": 96.923828125, "epoch": 26, "n_parameters": 319077484}
{"train_lr": 0.000468610054187941, "train_loss_total": 0.7752206437289715, "train_loss_cls": 0.7752206437289715, "train_acc1_cls": 92.919921875, "train_acc5_cls": 97.998046875, "epoch": 27, "n_parameters": 319077484}
{"train_lr": 0.0004373390098840157, "train_loss_total": 0.7530666589736938, "train_loss_cls": 0.7530666589736938, "train_acc1_cls": 92.67578125, "train_acc5_cls": 97.900390625, "epoch": 28, "n_parameters": 319077484}
{"train_lr": 0.00040631527961371063, "train_loss_total": 0.7283459641039371, "train_loss_cls": 0.7283459641039371, "train_acc1_cls": 93.798828125, "train_acc5_cls": 97.55859375, "epoch": 29, "n_parameters": 319077484}
{"train_lr": 0.0003756612998670084, "train_loss_total": 0.7213576026260853, "train_loss_cls": 0.7213576026260853, "train_acc1_cls": 93.9453125, "train_acc5_cls": 98.388671875, "epoch": 30, "n_parameters": 319077484}
{"train_lr": 0.0003454980478974983, "train_loss_total": 0.6576855592429638, "train_loss_cls": 0.6576855592429638, "train_acc1_cls": 94.04296875, "train_acc5_cls": 98.291015625, "epoch": 31, "n_parameters": 319077484}
{"train_lr": 0.0003159445642804246, "train_loss_total": 0.6349676437675953, "train_loss_cls": 0.6349676437675953, "train_acc1_cls": 94.921875, "train_acc5_cls": 98.53515625, "epoch": 32, "n_parameters": 319077484}
{"train_lr": 0.00028711748311392157, "train_loss_total": 0.6204731166362762, "train_loss_cls": 0.6204731166362762, "train_acc1_cls": 94.580078125, "train_acc5_cls": 98.583984375, "epoch": 33, "n_parameters": 319077484}
{"train_lr": 0.0002591305717175128, "train_loss_total": 0.6056483015418053, "train_loss_cls": 0.6056483015418053, "train_acc1_cls": 95.21484375, "train_acc5_cls": 98.53515625, "epoch": 34, "n_parameters": 319077484}
{"train_lr": 0.00023209428164447642, "train_loss_total": 0.5708938091993332, "train_loss_cls": 0.5708938091993332, "train_acc1_cls": 95.8984375, "train_acc5_cls": 98.6328125, "epoch": 35, "n_parameters": 319077484}
{"train_lr": 0.00020611531278002496, "train_loss_total": 0.5495995245873928, "train_loss_cls": 0.5495995245873928, "train_acc1_cls": 96.38671875, "train_acc5_cls": 98.974609375, "epoch": 36, "n_parameters": 319077484}
{"train_lr": 0.00018129619224560386, "train_loss_total": 0.555878184735775, "train_loss_cls": 0.555878184735775, "train_acc1_cls": 95.99609375, "train_acc5_cls": 99.12109375, "epoch": 37, "n_parameters": 319077484}
{"train_lr": 0.00015773486977118528, "train_loss_total": 0.5195257551968098, "train_loss_cls": 0.5195257551968098, "train_acc1_cls": 96.2890625, "train_acc5_cls": 99.0234375, "epoch": 38, "n_parameters": 319077484}
{"train_lr": 0.00013552433113243144, "train_loss_total": 0.5135317333042622, "train_loss_cls": 0.5135317333042622, "train_acc1_cls": 96.09375, "train_acc5_cls": 99.4140625, "epoch": 39, "n_parameters": 319077484}
{"train_lr": 0.00011475223117831931, "train_loss_total": 0.49647051095962524, "train_loss_cls": 0.49647051095962524, "train_acc1_cls": 96.58203125, "train_acc5_cls": 99.0234375, "epoch": 40, "n_parameters": 319077484}
{"train_lr": 9.550054789749821e-05, "train_loss_total": 0.4919010400772095, "train_loss_cls": 0.4919010400772095, "train_acc1_cls": 96.484375, "train_acc5_cls": 99.4140625, "epoch": 41, "n_parameters": 319077484}
{"train_lr": 7.784525888862008e-05, "train_loss_total": 0.518489170819521, "train_loss_cls": 0.518489170819521, "train_acc1_cls": 96.484375, "train_acc5_cls": 98.828125, "epoch": 42, "n_parameters": 319077484}
{"train_lr": 6.185604151146843e-05, "train_loss_total": 0.4613267034292221, "train_loss_cls": 0.4613267034292221, "train_acc1_cls": 97.216796875, "train_acc5_cls": 99.4140625, "epoch": 43, "n_parameters": 319077484}
{"train_lr": 4.759599790225266e-05, "train_loss_total": 0.5067677069455385, "train_loss_cls": 0.5067677069455385, "train_acc1_cls": 96.044921875, "train_acc5_cls": 99.169921875, "epoch": 44, "n_parameters": 319077484}
{"train_lr": 3.512140593830377e-05, "train_loss_total": 0.4996287878602743, "train_loss_cls": 0.4996287878602743, "train_acc1_cls": 96.240234375, "train_acc5_cls": 99.072265625, "epoch": 45, "n_parameters": 319077484}
{"train_lr": 2.4481497135004713e-05, "train_loss_total": 0.46628410555422306, "train_loss_cls": 0.46628410555422306, "train_acc1_cls": 97.265625, "train_acc5_cls": 99.560546875, "epoch": 46, "n_parameters": 319077484}
{"train_lr": 1.571826235149016e-05, "train_loss_total": 0.4771138224750757, "train_loss_cls": 0.4771138224750757, "train_acc1_cls": 96.6796875, "train_acc5_cls": 99.658203125, "epoch": 47, "n_parameters": 319077484}
{"train_lr": 8.866286071909284e-06, "train_loss_total": 0.47403218038380146, "train_loss_cls": 0.47403218038380146, "train_acc1_cls": 96.728515625, "train_acc5_cls": 99.4140625, "epoch": 48, "n_parameters": 319077484}
{"train_lr": 3.95260991626769e-06, "train_loss_total": 0.4677525404840708, "train_loss_cls": 0.4677525404840708, "train_acc1_cls": 96.38671875, "train_acc5_cls": 99.0234375, "epoch": 49, "n_parameters": 319077484}


Namespace(batch_size=128, epochs=50, bce_loss=True, unscale_lr=True, rec=False, freeze=True, model='jigsaw_sma
ll_patch56_336', input_size=336, permcls=1000, drop=0.0, drop_path=0.1, model_ema=True, model_ema_decay=0.9999
6, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight
_decay=0.05, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, mi
n_lr=1e-08, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_ji
tter=0.3, aa='rand-m9-mstd0.5-inc1', smoothing=None, train_interpolation='bicubic', repeated_aug=True, train_m
ode=True, ThreeAugment=False, src=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cut
mix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', teacher_model='regnety
_160', teacher_path='', distillation_type='none', distillation_alpha=0.5, distillation_tau=1.0, finetune='./ou
tputs/in1k_jigsaw_small_patch56_336_e30_c1000/best_checkpoint.pth', attn_only=False, data_path='/workspace/dat
a/imagenet/ILSVRC/Data/CLS-LOC', data_set='IMNET', nb_classes=1000, inat_category='name', output_dir='./output
s/in1k_jigsaw_small_patch56_336_e30_c1000frcl50', device='cuda', seed=0, resume='', start_epoch=0, eval=False,
 eval_crop_ratio=0.875, dist_eval=False, num_workers=10, pin_mem=True, world_size=8, dist_url='env://', local_
rank=0, use_jigsaw=True, use_cls=True, lambda_rec=0.1, mask_ratio=0.0, rank=0, gpu=0, distributed=True, dist_b
ackend='nccl')
Loading classification branch: True
Loading classification branch: True
Creating model: jigsaw_small_patch56_336
Removing key cls_head.0.weight from pretrained checkpoint
Removing key cls_head.0.bias from pretrained checkpoint
number of params: 319077484
using bce loss
Start training for 50 epochs
Epoch: [0]  [0/2]  eta: 0:00:14  lr: 0.001000  loss_total: 4.4821 (4.4821)  loss_cls: 4.4821 (4.4821)  acc1_cl
s: 1.5625 (1.5625)  acc5_cls: 4.6875 (4.6875)  time: 7.3122  data: 4.3599  max mem: 10232
Epoch: [0]  [1/2]  eta: 0:00:03  lr: 0.001000  loss_total: 3.8189 (4.1505)  loss_cls: 3.8189 (4.1505)  acc1_cl
s: 1.5625 (7.8125)  acc5_cls: 4.6875 (19.1406)  time: 3.7733  data: 2.1800  max mem: 10232
Epoch: [0] Total time: 0:00:07 (3.8750 s / it)
Averaged stats: lr: 0.001000  loss_total: 3.8189 (4.1624)  loss_cls: 3.8189 (4.1624)  acc1_cls: 1.5625 (7.1289
)  acc5_cls: 4.6875 (19.4824)
Test:  [0/4]  eta: 0:00:14  loss: 87.0935 (87.0935)  acc1_cls: 6.2500 (6.2500)  acc5_cls: 7.8125 (7.8125)  tim
e: 3.5677  data: 3.4205  max mem: 10232
Test:  [3/4]  eta: 0:00:01  loss: 77.1488 (79.8643)  acc1_cls: 0.0000 (3.3898)  acc5_cls: 7.8125 (9.9576)  tim
e: 1.0215  data: 0.9275  max mem: 10232
Test: Total time: 0:00:04 (1.0700 s / it)
* Batch-avg:             Cls Acc1: 3.390,                Cls Acc5: 9.958,                loss 79.864
Max acc1_cls: 3.39%
Epoch: [1]  [0/2]  eta: 0:00:08  lr: 0.001000  loss_total: 3.8187 (3.8187)  loss_cls: 3.8187 (3.8187)  acc1_cl
s: 19.5312 (19.5312)  acc5_cls: 32.8125 (32.8125)  time: 4.2986  data: 4.0903  max mem: 10232
Epoch: [1]  [1/2]  eta: 0:00:02  lr: 0.001000  loss_total: 3.4843 (3.6515)  loss_cls: 3.4843 (3.6515)  acc1_cl
s: 19.5312 (21.0938)  acc5_cls: 32.8125 (35.9375)  time: 2.2644  data: 2.0452  max mem: 10232
Epoch: [1] Total time: 0:00:04 (2.4026 s / it)
Averaged stats: lr: 0.001000  loss_total: 3.4843 (3.7496)  loss_cls: 3.4843 (3.7496)  acc1_cls: 19.5312 (17.91
99)  acc5_cls: 32.8125 (33.5449)
Test:  [0/4]  eta: 0:00:13  loss: 43.4722 (43.4722)  acc1_cls: 5.4688 (5.4688)  acc5_cls: 14.8438 (14.8438)  t
ime: 3.4069  data: 3.3529  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 34.9746 (37.4685)  acc1_cls: 3.4091 (4.0254)  acc5_cls: 14.8438 (13.7712)  t
ime: 0.9087  data: 0.8383  max mem: 10232
Test: Total time: 0:00:03 (0.9594 s / it)
* Batch-avg:             Cls Acc1: 4.025,                Cls Acc5: 13.771,                loss 37.469
Max acc1_cls: 4.03%
Epoch: [2]  [0/2]  eta: 0:00:08  lr: 0.000999  loss_total: 3.5526 (3.5526)  loss_cls: 3.5526 (3.5526)  acc1_cl
s: 25.0000 (25.0000)  acc5_cls: 35.1562 (35.1562)  time: 4.0674  data: 3.8644  max mem: 10232
Epoch: [2]  [1/2]  eta: 0:00:02  lr: 0.000999  loss_total: 3.5438 (3.5482)  loss_cls: 3.5438 (3.5482)  acc1_cl
s: 21.8750 (23.4375)  acc5_cls: 35.1562 (38.6719)  time: 2.1484  data: 1.9323  max mem: 10232
Epoch: [2] Total time: 0:00:04 (2.2969 s / it)
Averaged stats: lr: 0.000999  loss_total: 3.5438 (3.5234)  loss_cls: 3.5438 (3.5234)  acc1_cls: 21.8750 (25.09
77)  acc5_cls: 35.1562 (41.1621)
Test:  [0/4]  eta: 0:00:13  loss: 26.9392 (26.9392)  acc1_cls: 1.5625 (1.5625)  acc5_cls: 17.1875 (17.1875)  t
ime: 3.3187  data: 3.2656  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 25.0148 (25.6881)  acc1_cls: 1.5625 (3.1780)  acc5_cls: 11.3636 (13.7712)  t
ime: 0.8868  data: 0.8353  max mem: 10232
Test: Total time: 0:00:03 (0.9601 s / it)
* Batch-avg:             Cls Acc1: 3.178,                Cls Acc5: 13.771,                loss 25.688
Max acc1_cls: 4.03%
Epoch: [3]  [0/2]  eta: 0:00:10  lr: 0.000996  loss_total: 3.4133 (3.4133)  loss_cls: 3.4133 (3.4133)  acc1_cl
s: 26.5625 (26.5625)  acc5_cls: 39.8438 (39.8438)  time: 5.2067  data: 5.0150  max mem: 10232
Epoch: [3]  [1/2]  eta: 0:00:02  lr: 0.000996  loss_total: 3.3268 (3.3701)  loss_cls: 3.3268 (3.3701)  acc1_cl
s: 26.5625 (28.5156)  acc5_cls: 39.8438 (42.9688)  time: 2.7197  data: 2.5075  max mem: 10232
Epoch: [3] Total time: 0:00:05 (2.8621 s / it)
Averaged stats: lr: 0.000996  loss_total: 3.3268 (3.3355)  loss_cls: 3.3268 (3.3355)  acc1_cls: 26.5625 (29.24
80)  acc5_cls: 39.8438 (44.8242)
Test:  [0/4]  eta: 0:00:13  loss: 29.6453 (29.6453)  acc1_cls: 0.0000 (0.0000)  acc5_cls: 4.6875 (4.6875)  tim
e: 3.2589  data: 3.2049  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 24.7725 (26.0884)  acc1_cls: 0.0000 (2.9661)  acc5_cls: 13.2812 (15.2542)  t
ime: 0.8709  data: 0.8013  max mem: 10232
Test: Total time: 0:00:03 (0.9509 s / it)
* Batch-avg:             Cls Acc1: 2.966,                Cls Acc5: 15.254,                loss 26.088
Max acc1_cls: 4.03%
Epoch: [4]  [0/2]  eta: 0:00:11  lr: 0.000991  loss_total: 3.2178 (3.2178)  loss_cls: 3.2178 (3.2178)  acc1_cl
s: 28.9062 (28.9062)  acc5_cls: 46.8750 (46.8750)  time: 5.5699  data: 4.7984  max mem: 10232
Epoch: [4]  [1/2]  eta: 0:00:02  lr: 0.000991  loss_total: 2.9665 (3.0921)  loss_cls: 2.9665 (3.0921)  acc1_cl
s: 28.9062 (32.4219)  acc5_cls: 46.8750 (51.9531)  time: 2.9020  data: 2.3993  max mem: 10232
Epoch: [4] Total time: 0:00:06 (3.0580 s / it)
Averaged stats: lr: 0.000991  loss_total: 2.9665 (3.0433)  loss_cls: 2.9665 (3.0433)  acc1_cls: 28.9062 (33.64
26)  acc5_cls: 46.8750 (53.4668)
Test:  [0/4]  eta: 0:00:12  loss: 17.3748 (17.3748)  acc1_cls: 4.6875 (4.6875)  acc5_cls: 10.1562 (10.1562)  t
ime: 3.1194  data: 3.0647  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 14.6507 (14.2142)  acc1_cls: 4.6875 (6.9915)  acc5_cls: 17.1875 (18.8559)  t
ime: 0.8679  data: 0.8150  max mem: 10232
Test: Total time: 0:00:03 (0.9383 s / it)
* Batch-avg:             Cls Acc1: 6.992,                Cls Acc5: 18.856,                loss 14.214
Max acc1_cls: 6.99%
Epoch: [5]  [0/2]  eta: 0:00:08  lr: 0.000984  loss_total: 3.0219 (3.0219)  loss_cls: 3.0219 (3.0219)  acc1_cl
s: 35.1562 (35.1562)  acc5_cls: 53.1250 (53.1250)  time: 4.3401  data: 4.1442  max mem: 10232
Epoch: [5]  [1/2]  eta: 0:00:02  lr: 0.000984  loss_total: 2.8277 (2.9248)  loss_cls: 2.8277 (2.9248)  acc1_cl
s: 35.1562 (39.4531)  acc5_cls: 53.1250 (56.6406)  time: 2.2861  data: 2.0722  max mem: 10232
Epoch: [5] Total time: 0:00:04 (2.4454 s / it)
Averaged stats: lr: 0.000984  loss_total: 2.8277 (2.9579)  loss_cls: 2.8277 (2.9579)  acc1_cls: 35.1562 (37.79
30)  acc5_cls: 53.1250 (55.6152)
Test:  [0/4]  eta: 0:00:14  loss: 19.0959 (19.0959)  acc1_cls: 0.7812 (0.7812)  acc5_cls: 24.2188 (24.2188)  t
ime: 3.5928  data: 3.5375  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 18.2931 (17.7915)  acc1_cls: 0.7812 (2.3305)  acc5_cls: 20.3125 (23.5169)  t
ime: 0.9547  data: 0.8844  max mem: 10232
Test: Total time: 0:00:04 (1.0550 s / it)
* Batch-avg:             Cls Acc1: 2.331,                Cls Acc5: 23.517,                loss 17.792
Max acc1_cls: 6.99%
Epoch: [6]  [0/2]  eta: 0:00:10  lr: 0.000976  loss_total: 2.7909 (2.7909)  loss_cls: 2.7909 (2.7909)  acc1_cl
s: 43.7500 (43.7500)  acc5_cls: 61.7188 (61.7188)  time: 5.4532  data: 5.0032  max mem: 10232
Epoch: [6]  [1/2]  eta: 0:00:02  lr: 0.000976  loss_total: 2.7909 (2.9028)  loss_cls: 2.7909 (2.9028)  acc1_cl
s: 43.7500 (44.5312)  acc5_cls: 55.4688 (58.5938)  time: 2.8445  data: 2.5016  max mem: 10232
Epoch: [6] Total time: 0:00:05 (2.9840 s / it)
Averaged stats: lr: 0.000976  loss_total: 2.7909 (2.8678)  loss_cls: 2.7909 (2.8678)  acc1_cls: 43.7500 (43.50
59)  acc5_cls: 55.4688 (57.8613)
Test:  [0/4]  eta: 0:00:13  loss: 13.3246 (13.3246)  acc1_cls: 3.1250 (3.1250)  acc5_cls: 20.3125 (20.3125)  t
ime: 3.3854  data: 3.3323  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 13.1632 (12.9975)  acc1_cls: 1.1364 (4.2373)  acc5_cls: 18.7500 (17.1610)  t
ime: 0.9062  data: 0.8545  max mem: 10232
Test: Total time: 0:00:04 (1.0192 s / it)
* Batch-avg:             Cls Acc1: 4.237,                Cls Acc5: 17.161,                loss 12.997
Max acc1_cls: 6.99%
Epoch: [7]  [0/2]  eta: 0:00:11  lr: 0.000965  loss_total: 2.6657 (2.6657)  loss_cls: 2.6657 (2.6657)  acc1_cl
s: 46.0938 (46.0938)  acc5_cls: 62.5000 (62.5000)  time: 5.7510  data: 5.1163  max mem: 10232
Epoch: [7]  [1/2]  eta: 0:00:02  lr: 0.000965  loss_total: 2.6657 (2.6955)  loss_cls: 2.6657 (2.6955)  acc1_cl
s: 45.3125 (45.7031)  acc5_cls: 61.7188 (62.1094)  time: 2.9928  data: 2.5582  max mem: 10232
Epoch: [7] Total time: 0:00:06 (3.1600 s / it)
Averaged stats: lr: 0.000965  loss_total: 2.6657 (2.6782)  loss_cls: 2.6657 (2.6782)  acc1_cls: 45.3125 (44.82
42)  acc5_cls: 61.7188 (61.6699)
Test:  [0/4]  eta: 0:00:14  loss: 8.8192 (8.8192)  acc1_cls: 10.9375 (10.9375)  acc5_cls: 24.2188 (24.2188)  t
ime: 3.6517  data: 3.5985  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 9.1123 (9.6902)  acc1_cls: 5.6818 (7.8390)  acc5_cls: 19.5312 (20.3390)  tim
e: 0.9670  data: 0.9016  max mem: 10232
Test: Total time: 0:00:04 (1.0685 s / it)
* Batch-avg:             Cls Acc1: 7.839,                Cls Acc5: 20.339,                loss 9.690
Max acc1_cls: 7.84%
Epoch: [8]  [0/2]  eta: 0:00:09  lr: 0.000952  loss_total: 2.5798 (2.5798)  loss_cls: 2.5798 (2.5798)  acc1_cl
s: 42.9688 (42.9688)  acc5_cls: 67.1875 (67.1875)  time: 4.5231  data: 4.2922  max mem: 10232
Epoch: [8]  [1/2]  eta: 0:00:02  lr: 0.000952  loss_total: 2.2673 (2.4236)  loss_cls: 2.2673 (2.4236)  acc1_cl
s: 42.9688 (52.3438)  acc5_cls: 67.1875 (71.8750)  time: 2.3609  data: 2.1462  max mem: 10232
Epoch: [8] Total time: 0:00:04 (2.4486 s / it)
Averaged stats: lr: 0.000952  loss_total: 2.2673 (2.4299)  loss_cls: 2.2673 (2.4299)  acc1_cls: 42.9688 (51.26
95)  acc5_cls: 67.1875 (71.2891)
Test:  [0/4]  eta: 0:00:14  loss: 7.3437 (7.3437)  acc1_cls: 12.5000 (12.5000)  acc5_cls: 29.6875 (29.6875)  t
ime: 3.5105  data: 3.4567  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 8.7312 (8.7318)  acc1_cls: 10.1562 (9.1102)  acc5_cls: 16.4062 (21.1864)  ti
me: 0.9367  data: 0.8850  max mem: 10232
Test: Total time: 0:00:04 (1.0480 s / it)
* Batch-avg:             Cls Acc1: 9.110,                Cls Acc5: 21.186,                loss 8.732
Max acc1_cls: 9.11%
Epoch: [9]  [0/2]  eta: 0:00:09  lr: 0.000938  loss_total: 2.3244 (2.3244)  loss_cls: 2.3244 (2.3244)  acc1_cl
s: 50.7812 (50.7812)  acc5_cls: 71.0938 (71.0938)  time: 4.9119  data: 4.7170  max mem: 10232
Epoch: [9]  [1/2]  eta: 0:00:02  lr: 0.000938  loss_total: 2.1718 (2.2481)  loss_cls: 2.1718 (2.2481)  acc1_cl
s: 50.7812 (56.6406)  acc5_cls: 71.0938 (72.2656)  time: 2.5739  data: 2.3585  max mem: 10232
Epoch: [9] Total time: 0:00:05 (2.7405 s / it)
Averaged stats: lr: 0.000938  loss_total: 2.1718 (2.2325)  loss_cls: 2.1718 (2.2325)  acc1_cls: 50.7812 (56.78
71)  acc5_cls: 71.0938 (74.8535)
Test:  [0/4]  eta: 0:00:14  loss: 5.3345 (5.3345)  acc1_cls: 15.6250 (15.6250)  acc5_cls: 35.1562 (35.1562)  t
ime: 3.7158  data: 3.6607  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 6.4710 (6.6463)  acc1_cls: 13.6364 (13.9831)  acc5_cls: 27.3438 (30.2966)  t
ime: 0.9844  data: 0.9152  max mem: 10232
Test: Total time: 0:00:04 (1.0905 s / it)
* Batch-avg:             Cls Acc1: 13.983,                Cls Acc5: 30.297,                loss 6.646
Max acc1_cls: 13.98%
Epoch: [10]  [0/2]  eta: 0:00:09  lr: 0.000922  loss_total: 2.1103 (2.1103)  loss_cls: 2.1103 (2.1103)  acc1_c
ls: 63.2812 (63.2812)  acc5_cls: 78.9062 (78.9062)  time: 4.6595  data: 4.4654  max mem: 10232
Epoch: [10]  [1/2]  eta: 0:00:02  lr: 0.000922  loss_total: 2.0458 (2.0780)  loss_cls: 2.0458 (2.0780)  acc1_c
ls: 59.3750 (61.3281)  acc5_cls: 78.1250 (78.5156)  time: 2.4504  data: 2.2327  max mem: 10232
Epoch: [10] Total time: 0:00:05 (2.6074 s / it)
Averaged stats: lr: 0.000922  loss_total: 2.0458 (2.0617)  loss_cls: 2.0458 (2.0617)  acc1_cls: 59.3750 (62.98
83)  acc5_cls: 78.1250 (78.9062)
Test:  [0/4]  eta: 0:00:15  loss: 4.4272 (4.4272)  acc1_cls: 17.9688 (17.9688)  acc5_cls: 46.0938 (46.0938)  t
ime: 3.8997  data: 3.8446  max mem: 10232
Test:  [3/4]  eta: 0:00:01  loss: 4.8045 (5.4683)  acc1_cls: 17.1875 (16.1017)  acc5_cls: 36.7188 (38.1356)  t
ime: 1.0305  data: 0.9612  max mem: 10232
Test: Total time: 0:00:04 (1.1305 s / it)
* Batch-avg:             Cls Acc1: 16.102,                Cls Acc5: 38.136,                loss 5.468
Max acc1_cls: 16.10%
Epoch: [11]  [0/2]  eta: 0:00:09  lr: 0.000905  loss_total: 2.1454 (2.1454)  loss_cls: 2.1454 (2.1454)  acc1_c
ls: 58.5938 (58.5938)  acc5_cls: 75.7812 (75.7812)  time: 4.7947  data: 4.6044  max mem: 10232
Epoch: [11]  [1/2]  eta: 0:00:02  lr: 0.000905  loss_total: 2.0250 (2.0852)  loss_cls: 2.0250 (2.0852)  acc1_c
ls: 58.5938 (61.3281)  acc5_cls: 75.7812 (78.1250)  time: 2.5331  data: 2.3022  max mem: 10232
Epoch: [11] Total time: 0:00:05 (2.7400 s / it)
Averaged stats: lr: 0.000905  loss_total: 2.0250 (2.0296)  loss_cls: 2.0250 (2.0296)  acc1_cls: 58.5938 (63.76
95)  acc5_cls: 75.7812 (78.7109)
Test:  [0/4]  eta: 0:00:14  loss: 4.1213 (4.1213)  acc1_cls: 25.7812 (25.7812)  acc5_cls: 46.8750 (46.8750)  t
ime: 3.5781  data: 3.5235  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 4.1213 (4.8587)  acc1_cls: 18.7500 (18.8559)  acc5_cls: 42.1875 (40.8898)  t
ime: 0.9994  data: 0.9518  max mem: 10232
Test: Total time: 0:00:04 (1.0497 s / it)
* Batch-avg:             Cls Acc1: 18.856,                Cls Acc5: 40.890,                loss 4.859
Max acc1_cls: 18.86%
Epoch: [12]  [0/2]  eta: 0:00:09  lr: 0.000885  loss_total: 1.8052 (1.8052)  loss_cls: 1.8052 (1.8052)  acc1_c
ls: 69.5312 (69.5312)  acc5_cls: 83.5938 (83.5938)  time: 4.5899  data: 4.3658  max mem: 10232
Epoch: [12]  [1/2]  eta: 0:00:02  lr: 0.000885  loss_total: 1.8052 (1.8087)  loss_cls: 1.8052 (1.8087)  acc1_c
ls: 65.6250 (67.5781)  acc5_cls: 83.5938 (83.5938)  time: 2.4129  data: 2.1830  max mem: 10232
Epoch: [12] Total time: 0:00:05 (2.5551 s / it)
Averaged stats: lr: 0.000885  loss_total: 1.8052 (1.7997)  loss_cls: 1.8052 (1.7997)  acc1_cls: 65.6250 (69.92
19)  acc5_cls: 83.5938 (83.3984)
Test:  [0/4]  eta: 0:00:13  loss: 4.3309 (4.3309)  acc1_cls: 21.8750 (21.8750)  acc5_cls: 39.8438 (39.8438)  t
ime: 3.4534  data: 3.3992  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 4.3309 (4.7163)  acc1_cls: 18.7500 (19.9153)  acc5_cls: 35.9375 (36.6525)  t
ime: 0.9566  data: 0.9031  max mem: 10232
Test: Total time: 0:00:04 (1.0204 s / it)
* Batch-avg:             Cls Acc1: 19.915,                Cls Acc5: 36.653,                loss 4.716
Max acc1_cls: 19.92%
Epoch: [13]  [0/2]  eta: 0:00:09  lr: 0.000864  loss_total: 1.7594 (1.7594)  loss_cls: 1.7594 (1.7594)  acc1_c
ls: 73.4375 (73.4375)  acc5_cls: 83.5938 (83.5938)  time: 4.7599  data: 4.5629  max mem: 10232
Epoch: [13]  [1/2]  eta: 0:00:02  lr: 0.000864  loss_total: 1.7530 (1.7562)  loss_cls: 1.7530 (1.7562)  acc1_c
ls: 69.5312 (71.4844)  acc5_cls: 81.2500 (82.4219)  time: 2.4970  data: 2.2815  max mem: 10232
Epoch: [13] Total time: 0:00:05 (2.6747 s / it)
Averaged stats: lr: 0.000864  loss_total: 1.7530 (1.7682)  loss_cls: 1.7530 (1.7682)  acc1_cls: 69.5312 (71.33
79)  acc5_cls: 81.2500 (83.6914)
Test:  [0/4]  eta: 0:00:13  loss: 4.4752 (4.4752)  acc1_cls: 18.7500 (18.7500)  acc5_cls: 39.8438 (39.8438)  t
ime: 3.4955  data: 3.4398  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 4.4752 (4.5262)  acc1_cls: 18.7500 (18.0085)  acc5_cls: 35.9375 (39.6186)  t
ime: 0.9319  data: 0.8696  max mem: 10232
Test: Total time: 0:00:04 (1.0317 s / it)
* Batch-avg:             Cls Acc1: 18.008,                Cls Acc5: 39.619,                loss 4.526
Max acc1_cls: 19.92%
Epoch: [14]  [0/2]  eta: 0:00:11  lr: 0.000842  loss_total: 1.8327 (1.8327)  loss_cls: 1.8327 (1.8327)  acc1_c
ls: 71.0938 (71.0938)  acc5_cls: 82.0312 (82.0312)  time: 5.5329  data: 4.9895  max mem: 10232
Epoch: [14]  [1/2]  eta: 0:00:02  lr: 0.000842  loss_total: 1.7558 (1.7943)  loss_cls: 1.7558 (1.7943)  acc1_c
ls: 68.7500 (69.9219)  acc5_cls: 82.0312 (82.4219)  time: 2.8820  data: 2.4948  max mem: 10232
Epoch: [14] Total time: 0:00:06 (3.0464 s / it)
Averaged stats: lr: 0.000842  loss_total: 1.7558 (1.7469)  loss_cls: 1.7558 (1.7469)  acc1_cls: 68.7500 (70.31
25)  acc5_cls: 82.0312 (84.0332)
Test:  [0/4]  eta: 0:00:14  loss: 4.1308 (4.1308)  acc1_cls: 19.5312 (19.5312)  acc5_cls: 51.5625 (51.5625)  t
ime: 3.6755  data: 3.6210  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 4.1308 (4.1362)  acc1_cls: 19.5312 (19.2797)  acc5_cls: 39.8438 (45.1271)  t
ime: 0.9703  data: 0.9114  max mem: 10232
Test: Total time: 0:00:04 (1.0451 s / it)
* Batch-avg:             Cls Acc1: 19.280,                Cls Acc5: 45.127,                loss 4.136
Max acc1_cls: 19.92%
Epoch: [15]  [0/2]  eta: 0:00:10  lr: 0.000819  loss_total: 1.4526 (1.4526)  loss_cls: 1.4526 (1.4526)  acc1_c
ls: 79.6875 (79.6875)  acc5_cls: 87.5000 (87.5000)  time: 5.4433  data: 5.2535  max mem: 10232
Epoch: [15]  [1/2]  eta: 0:00:02  lr: 0.000819  loss_total: 1.4526 (1.5041)  loss_cls: 1.4526 (1.5041)  acc1_c
ls: 71.8750 (75.7812)  acc5_cls: 87.5000 (88.6719)  time: 2.8372  data: 2.6268  max mem: 10232
Epoch: [15] Total time: 0:00:05 (2.9998 s / it)
Averaged stats: lr: 0.000819  loss_total: 1.4526 (1.5511)  loss_cls: 1.4526 (1.5511)  acc1_cls: 71.8750 (75.39
06)  acc5_cls: 87.5000 (87.5977)
Test:  [0/4]  eta: 0:00:15  loss: 4.1610 (4.1610)  acc1_cls: 16.4062 (16.4062)  acc5_cls: 49.2188 (49.2188)  t
ime: 3.8336  data: 3.7784  max mem: 10232
Test:  [3/4]  eta: 0:00:01  loss: 4.1140 (3.9873)  acc1_cls: 16.4062 (17.1610)  acc5_cls: 46.0938 (48.7288)  t
ime: 1.0150  data: 0.9447  max mem: 10232
Test: Total time: 0:00:04 (1.1073 s / it)
* Batch-avg:             Cls Acc1: 17.161,                Cls Acc5: 48.729,                loss 3.987
Max acc1_cls: 19.92%
Epoch: [16]  [0/2]  eta: 0:00:10  lr: 0.000794  loss_total: 1.5469 (1.5469)  loss_cls: 1.5469 (1.5469)  acc1_c
ls: 76.5625 (76.5625)  acc5_cls: 89.8438 (89.8438)  time: 5.4778  data: 4.7979  max mem: 10232
Epoch: [16]  [1/2]  eta: 0:00:02  lr: 0.000794  loss_total: 1.5469 (1.6541)  loss_cls: 1.5469 (1.6541)  acc1_c
ls: 66.4062 (71.4844)  acc5_cls: 82.0312 (85.9375)  time: 2.9350  data: 2.3990  max mem: 10232
Epoch: [16] Total time: 0:00:06 (3.0692 s / it)
Averaged stats: lr: 0.000794  loss_total: 1.5469 (1.5604)  loss_cls: 1.5469 (1.5604)  acc1_cls: 66.4062 (74.70
70)  acc5_cls: 82.0312 (88.1348)
Test:  [0/4]  eta: 0:00:14  loss: 3.9254 (3.9254)  acc1_cls: 16.4062 (16.4062)  acc5_cls: 47.6562 (47.6562)  t
ime: 3.5225  data: 3.4674  max mem: 10232
Test:  [3/4]  eta: 0:00:01  loss: 3.9254 (3.7782)  acc1_cls: 16.4062 (15.6780)  acc5_cls: 49.2188 (53.3898)  t
ime: 1.0124  data: 0.9621  max mem: 10232
Test: Total time: 0:00:04 (1.0594 s / it)
* Batch-avg:             Cls Acc1: 15.678,                Cls Acc5: 53.390,                loss 3.778
Max acc1_cls: 19.92%
Epoch: [17]  [0/2]  eta: 0:00:10  lr: 0.000768  loss_total: 1.6059 (1.6059)  loss_cls: 1.6059 (1.6059)  acc1_c
ls: 75.7812 (75.7812)  acc5_cls: 88.2812 (88.2812)  time: 5.3903  data: 5.1952  max mem: 10232
Epoch: [17]  [1/2]  eta: 0:00:02  lr: 0.000768  loss_total: 1.2858 (1.4458)  loss_cls: 1.2858 (1.4458)  acc1_c
ls: 75.7812 (78.1250)  acc5_cls: 88.2812 (92.5781)  time: 2.8236  data: 2.5976  max mem: 10232
Epoch: [17] Total time: 0:00:05 (2.9674 s / it)
Averaged stats: lr: 0.000768  loss_total: 1.2858 (1.3586)  loss_cls: 1.2858 (1.3586)  acc1_cls: 75.7812 (80.56
64)  acc5_cls: 88.2812 (92.2363)
Test:  [0/4]  eta: 0:00:13  loss: 3.5294 (3.5294)  acc1_cls: 21.0938 (21.0938)  acc5_cls: 58.5938 (58.5938)  t
ime: 3.4893  data: 3.4334  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 3.5294 (3.4625)  acc1_cls: 19.5312 (19.2797)  acc5_cls: 58.5938 (59.5339)  t
ime: 0.9692  data: 0.9149  max mem: 10232
Test: Total time: 0:00:04 (1.0304 s / it)
* Batch-avg:             Cls Acc1: 19.280,                Cls Acc5: 59.534,                loss 3.463
Max acc1_cls: 19.92%
Epoch: [18]  [0/2]  eta: 0:00:11  lr: 0.000741  loss_total: 1.3584 (1.3584)  loss_cls: 1.3584 (1.3584)  acc1_c
ls: 83.5938 (83.5938)  acc5_cls: 92.1875 (92.1875)  time: 5.6065  data: 5.1319  max mem: 10232
Epoch: [18]  [1/2]  eta: 0:00:02  lr: 0.000741  loss_total: 1.2280 (1.2932)  loss_cls: 1.2280 (1.2932)  acc1_c
ls: 83.5938 (84.3750)  acc5_cls: 92.1875 (92.5781)  time: 2.9200  data: 2.5660  max mem: 10232
Epoch: [18] Total time: 0:00:06 (3.0538 s / it)
Averaged stats: lr: 0.000741  loss_total: 1.2280 (1.2917)  loss_cls: 1.2280 (1.2917)  acc1_cls: 83.5938 (82.71
48)  acc5_cls: 92.1875 (90.9180)
Test:  [0/4]  eta: 0:00:15  loss: 3.2074 (3.2074)  acc1_cls: 21.8750 (21.8750)  acc5_cls: 64.8438 (64.8438)  t
ime: 3.9577  data: 3.9045  max mem: 10232
Test:  [3/4]  eta: 0:00:01  loss: 3.1779 (3.1714)  acc1_cls: 21.8750 (22.4576)  acc5_cls: 63.2812 (63.5593)  t
ime: 1.0457  data: 0.9762  max mem: 10232
Test: Total time: 0:00:04 (1.1749 s / it)
* Batch-avg:             Cls Acc1: 22.458,                Cls Acc5: 63.559,                loss 3.171
Max acc1_cls: 22.46%
Epoch: [19]  [0/2]  eta: 0:00:10  lr: 0.000713  loss_total: 1.2428 (1.2428)  loss_cls: 1.2428 (1.2428)  acc1_c
ls: 84.3750 (84.3750)  acc5_cls: 94.5312 (94.5312)  time: 5.0769  data: 4.8663  max mem: 10232
Epoch: [19]  [1/2]  eta: 0:00:02  lr: 0.000713  loss_total: 1.1471 (1.1950)  loss_cls: 1.1471 (1.1950)  acc1_c
ls: 84.3750 (86.3281)  acc5_cls: 93.7500 (94.1406)  time: 2.6544  data: 2.4332  max mem: 10232
Epoch: [19] Total time: 0:00:05 (2.7855 s / it)
Averaged stats: lr: 0.000713  loss_total: 1.1471 (1.1994)  loss_cls: 1.1471 (1.1994)  acc1_cls: 84.3750 (83.88
67)  acc5_cls: 93.7500 (92.8223)
Test:  [0/4]  eta: 0:00:14  loss: 2.8647 (2.8647)  acc1_cls: 27.3438 (27.3438)  acc5_cls: 66.4062 (66.4062)  t
ime: 3.5300  data: 3.4753  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.8647 (2.8872)  acc1_cls: 27.3438 (26.6949)  acc5_cls: 66.4062 (66.5254)  t
ime: 0.9459  data: 0.8918  max mem: 10232
Test: Total time: 0:00:04 (1.0626 s / it)
* Batch-avg:             Cls Acc1: 26.695,                Cls Acc5: 66.525,                loss 2.887
Max acc1_cls: 26.69%
Epoch: [20]  [0/2]  eta: 0:00:09  lr: 0.000684  loss_total: 1.1303 (1.1303)  loss_cls: 1.1303 (1.1303)  acc1_c
ls: 87.5000 (87.5000)  acc5_cls: 93.7500 (93.7500)  time: 4.7758  data: 4.5274  max mem: 10232
Epoch: [20]  [1/2]  eta: 0:00:02  lr: 0.000684  loss_total: 1.1303 (1.1623)  loss_cls: 1.1303 (1.1623)  acc1_c
ls: 81.2500 (84.3750)  acc5_cls: 93.7500 (94.5312)  time: 2.4844  data: 2.2637  max mem: 10232
Epoch: [20] Total time: 0:00:05 (2.6565 s / it)
Averaged stats: lr: 0.000684  loss_total: 1.1303 (1.1505)  loss_cls: 1.1303 (1.1505)  acc1_cls: 81.2500 (85.30
27)  acc5_cls: 93.7500 (94.2871)
Test:  [0/4]  eta: 0:00:13  loss: 2.5959 (2.5959)  acc1_cls: 30.4688 (30.4688)  acc5_cls: 71.0938 (71.0938)  t
ime: 3.3058  data: 3.2486  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.5959 (2.5936)  acc1_cls: 30.4688 (31.7797)  acc5_cls: 71.0938 (71.1864)  t
ime: 0.9629  data: 0.9136  max mem: 10232
Test: Total time: 0:00:04 (1.0172 s / it)
* Batch-avg:             Cls Acc1: 31.780,                Cls Acc5: 71.186,                loss 2.594
Max acc1_cls: 31.78%
Epoch: [21]  [0/2]  eta: 0:00:08  lr: 0.000655  loss_total: 1.0926 (1.0926)  loss_cls: 1.0926 (1.0926)  acc1_c
ls: 89.0625 (89.0625)  acc5_cls: 93.7500 (93.7500)  time: 4.1587  data: 3.9531  max mem: 10232
Epoch: [21]  [1/2]  eta: 0:00:02  lr: 0.000655  loss_total: 1.0926 (1.1025)  loss_cls: 1.0926 (1.1025)  acc1_c
ls: 88.2812 (88.6719)  acc5_cls: 92.9688 (93.3594)  time: 2.1917  data: 1.9766  max mem: 10232
Epoch: [21] Total time: 0:00:04 (2.3553 s / it)
Averaged stats: lr: 0.000655  loss_total: 1.0926 (1.0825)  loss_cls: 1.0926 (1.0825)  acc1_cls: 88.2812 (86.81
64)  acc5_cls: 92.9688 (94.2871)
Test:  [0/4]  eta: 0:00:12  loss: 2.3632 (2.3632)  acc1_cls: 33.5938 (33.5938)  acc5_cls: 72.6562 (72.6562)  t
ime: 3.2265  data: 3.1719  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.3632 (2.3662)  acc1_cls: 33.5938 (35.3814)  acc5_cls: 72.6562 (73.9407)  t
ime: 0.9264  data: 0.8775  max mem: 10232
Test: Total time: 0:00:03 (0.9745 s / it)
* Batch-avg:             Cls Acc1: 35.381,                Cls Acc5: 73.941,                loss 2.366
Max acc1_cls: 35.38%
Epoch: [22]  [0/2]  eta: 0:00:08  lr: 0.000624  loss_total: 1.0317 (1.0317)  loss_cls: 1.0317 (1.0317)  acc1_c
ls: 92.1875 (92.1875)  acc5_cls: 96.8750 (96.8750)  time: 4.4315  data: 4.2388  max mem: 10232
Epoch: [22]  [1/2]  eta: 0:00:02  lr: 0.000624  loss_total: 0.9991 (1.0154)  loss_cls: 0.9991 (1.0154)  acc1_c
ls: 90.6250 (91.4062)  acc5_cls: 96.8750 (96.8750)  time: 2.3334  data: 2.1194  max mem: 10232
Epoch: [22] Total time: 0:00:04 (2.4944 s / it)
Averaged stats: lr: 0.000624  loss_total: 0.9991 (1.0124)  loss_cls: 0.9991 (1.0124)  acc1_cls: 90.6250 (88.76
95)  acc5_cls: 96.8750 (95.8008)
Test:  [0/4]  eta: 0:00:12  loss: 2.2110 (2.2110)  acc1_cls: 41.4062 (41.4062)  acc5_cls: 77.3438 (77.3438)  t
ime: 3.2030  data: 3.1486  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.2086 (2.1971)  acc1_cls: 40.6250 (41.1017)  acc5_cls: 75.0000 (75.8475)  t
ime: 0.8950  data: 0.8475  max mem: 10232
Test: Total time: 0:00:03 (0.9683 s / it)
* Batch-avg:             Cls Acc1: 41.102,                Cls Acc5: 75.847,                loss 2.197
Max acc1_cls: 41.10%
Epoch: [23]  [0/2]  eta: 0:00:08  lr: 0.000594  loss_total: 0.8412 (0.8412)  loss_cls: 0.8412 (0.8412)  acc1_c
ls: 91.4062 (91.4062)  acc5_cls: 97.6562 (97.6562)  time: 4.4823  data: 4.2663  max mem: 10232
Epoch: [23]  [1/2]  eta: 0:00:02  lr: 0.000594  loss_total: 0.8412 (0.9664)  loss_cls: 0.8412 (0.9664)  acc1_c
ls: 86.7188 (89.0625)  acc5_cls: 95.3125 (96.4844)  time: 2.3524  data: 2.1332  max mem: 10232
Epoch: [23] Total time: 0:00:05 (2.5133 s / it)
Averaged stats: lr: 0.000594  loss_total: 0.8412 (0.9502)  loss_cls: 0.8412 (0.9502)  acc1_cls: 86.7188 (89.94
14)  acc5_cls: 95.3125 (96.1914)
Test:  [0/4]  eta: 0:00:13  loss: 2.1462 (2.1462)  acc1_cls: 42.1875 (42.1875)  acc5_cls: 78.9062 (78.9062)  t
ime: 3.4229  data: 3.3681  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.1462 (2.1493)  acc1_cls: 40.6250 (41.9492)  acc5_cls: 78.9062 (76.4831)  t
ime: 0.9113  data: 0.8421  max mem: 10232
Test: Total time: 0:00:03 (0.9988 s / it)
* Batch-avg:             Cls Acc1: 41.949,                Cls Acc5: 76.483,                loss 2.149
Max acc1_cls: 41.95%
Epoch: [24]  [0/2]  eta: 0:00:08  lr: 0.000563  loss_total: 0.9962 (0.9962)  loss_cls: 0.9962 (0.9962)  acc1_c
ls: 88.2812 (88.2812)  acc5_cls: 92.1875 (92.1875)  time: 4.2521  data: 4.0347  max mem: 10232
Epoch: [24]  [1/2]  eta: 0:00:02  lr: 0.000563  loss_total: 0.9240 (0.9601)  loss_cls: 0.9240 (0.9601)  acc1_c
ls: 88.2812 (88.6719)  acc5_cls: 92.1875 (94.5312)  time: 2.2289  data: 2.0174  max mem: 10232
Epoch: [24] Total time: 0:00:04 (2.3676 s / it)
Averaged stats: lr: 0.000563  loss_total: 0.9240 (0.9446)  loss_cls: 0.9240 (0.9446)  acc1_cls: 88.2812 (89.11
13)  acc5_cls: 92.1875 (96.5820)
Test:  [0/4]  eta: 0:00:13  loss: 2.0938 (2.0938)  acc1_cls: 43.7500 (43.7500)  acc5_cls: 79.6875 (79.6875)  t
ime: 3.3507  data: 3.2962  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.0938 (2.1025)  acc1_cls: 39.0625 (43.2203)  acc5_cls: 79.6875 (77.3305)  t
ime: 0.8869  data: 0.8241  max mem: 10232
Test: Total time: 0:00:03 (0.9546 s / it)
* Batch-avg:             Cls Acc1: 43.220,                Cls Acc5: 77.331,                loss 2.102
Max acc1_cls: 43.22%
Epoch: [25]  [0/2]  eta: 0:00:08  lr: 0.000531  loss_total: 0.9624 (0.9624)  loss_cls: 0.9624 (0.9624)  acc1_c
ls: 90.6250 (90.6250)  acc5_cls: 94.5312 (94.5312)  time: 4.2943  data: 4.0915  max mem: 10232
Epoch: [25]  [1/2]  eta: 0:00:02  lr: 0.000531  loss_total: 0.9624 (0.9656)  loss_cls: 0.9624 (0.9656)  acc1_c
ls: 90.6250 (90.6250)  acc5_cls: 94.5312 (94.5312)  time: 2.2629  data: 2.0458  max mem: 10232
Epoch: [25] Total time: 0:00:04 (2.4073 s / it)
Averaged stats: lr: 0.000531  loss_total: 0.9624 (0.9095)  loss_cls: 0.9624 (0.9095)  acc1_cls: 90.6250 (90.77
15)  acc5_cls: 94.5312 (96.7285)
Test:  [0/4]  eta: 0:00:12  loss: 2.0573 (2.0573)  acc1_cls: 43.7500 (43.7500)  acc5_cls: 80.4688 (80.4688)  t
ime: 3.0967  data: 3.0419  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.0573 (2.1289)  acc1_cls: 35.9375 (41.9492)  acc5_cls: 79.5455 (78.3898)  t
ime: 0.8574  data: 0.8038  max mem: 10232
Test: Total time: 0:00:03 (0.9182 s / it)
* Batch-avg:             Cls Acc1: 41.949,                Cls Acc5: 78.390,                loss 2.129
Max acc1_cls: 43.22%
Epoch: [26]  [0/2]  eta: 0:00:10  lr: 0.000500  loss_total: 0.9528 (0.9528)  loss_cls: 0.9528 (0.9528)  acc1_c
ls: 88.2812 (88.2812)  acc5_cls: 94.5312 (94.5312)  time: 5.2037  data: 4.5984  max mem: 10232
Epoch: [26]  [1/2]  eta: 0:00:02  lr: 0.000500  loss_total: 0.8466 (0.8997)  loss_cls: 0.8466 (0.8997)  acc1_c
ls: 88.2812 (90.6250)  acc5_cls: 94.5312 (95.7031)  time: 2.7179  data: 2.2992  max mem: 10232
Epoch: [26] Total time: 0:00:05 (2.8819 s / it)
Averaged stats: lr: 0.000500  loss_total: 0.8466 (0.8663)  loss_cls: 0.8466 (0.8663)  acc1_cls: 88.2812 (90.72
27)  acc5_cls: 94.5312 (96.9238)
Test:  [0/4]  eta: 0:00:12  loss: 2.0459 (2.0459)  acc1_cls: 42.9688 (42.9688)  acc5_cls: 79.6875 (79.6875)  t
ime: 3.1734  data: 3.1189  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.0459 (2.1659)  acc1_cls: 31.2500 (39.1949)  acc5_cls: 76.1364 (78.8136)  t
ime: 0.8945  data: 0.8470  max mem: 10232
Test: Total time: 0:00:03 (0.9424 s / it)
* Batch-avg:             Cls Acc1: 39.195,                Cls Acc5: 78.814,                loss 2.166
Max acc1_cls: 43.22%
Epoch: [27]  [0/2]  eta: 0:00:10  lr: 0.000469  loss_total: 0.7615 (0.7615)  loss_cls: 0.7615 (0.7615)  acc1_c
ls: 92.9688 (92.9688)  acc5_cls: 97.6562 (97.6562)  time: 5.4000  data: 4.6940  max mem: 10232
Epoch: [27]  [1/2]  eta: 0:00:02  lr: 0.000469  loss_total: 0.7615 (0.8035)  loss_cls: 0.7615 (0.8035)  acc1_c
ls: 90.6250 (91.7969)  acc5_cls: 96.8750 (97.2656)  time: 2.8146  data: 2.3471  max mem: 10232
Epoch: [27] Total time: 0:00:05 (2.9624 s / it)
Averaged stats: lr: 0.000469  loss_total: 0.7615 (0.7752)  loss_cls: 0.7615 (0.7752)  acc1_cls: 90.6250 (92.91
99)  acc5_cls: 96.8750 (97.9980)
Test:  [0/4]  eta: 0:00:14  loss: 2.1223 (2.1223)  acc1_cls: 43.7500 (43.7500)  acc5_cls: 77.3438 (77.3438)  t
ime: 3.5364  data: 3.4813  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.1223 (2.2006)  acc1_cls: 33.5938 (39.4068)  acc5_cls: 72.7273 (76.9068)  t
ime: 0.9418  data: 0.8704  max mem: 10232
Test: Total time: 0:00:04 (1.0132 s / it)
* Batch-avg:             Cls Acc1: 39.407,                Cls Acc5: 76.907,                loss 2.201
Max acc1_cls: 43.22%
Epoch: [28]  [0/2]  eta: 0:00:10  lr: 0.000437  loss_total: 0.6759 (0.6759)  loss_cls: 0.6759 (0.6759)  acc1_c
ls: 96.0938 (96.0938)  acc5_cls: 99.2188 (99.2188)  time: 5.4229  data: 4.8559  max mem: 10232
Epoch: [28]  [1/2]  eta: 0:00:02  lr: 0.000437  loss_total: 0.6759 (0.7136)  loss_cls: 0.6759 (0.7136)  acc1_c
ls: 92.9688 (94.5312)  acc5_cls: 98.4375 (98.8281)  time: 2.8281  data: 2.4280  max mem: 10232
Epoch: [28] Total time: 0:00:05 (2.9939 s / it)
Averaged stats: lr: 0.000437  loss_total: 0.6759 (0.7531)  loss_cls: 0.6759 (0.7531)  acc1_cls: 92.9688 (92.67
58)  acc5_cls: 98.4375 (97.9004)
Test:  [0/4]  eta: 0:00:14  loss: 2.0274 (2.0274)  acc1_cls: 47.6562 (47.6562)  acc5_cls: 77.3438 (77.3438)  t
ime: 3.5947  data: 3.5412  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.0274 (2.0989)  acc1_cls: 39.8438 (43.2203)  acc5_cls: 74.2188 (78.1780)  t
ime: 0.9547  data: 0.8854  max mem: 10232
Test: Total time: 0:00:04 (1.0594 s / it)
* Batch-avg:             Cls Acc1: 43.220,                Cls Acc5: 78.178,                loss 2.099
Max acc1_cls: 43.22%
Epoch: [29]  [0/2]  eta: 0:00:08  lr: 0.000406  loss_total: 0.7825 (0.7825)  loss_cls: 0.7825 (0.7825)  acc1_c
ls: 89.8438 (89.8438)  acc5_cls: 97.6562 (97.6562)  time: 4.2293  data: 4.0269  max mem: 10232
Epoch: [29]  [1/2]  eta: 0:00:02  lr: 0.000406  loss_total: 0.7825 (0.7891)  loss_cls: 0.7825 (0.7891)  acc1_c
ls: 89.8438 (91.4062)  acc5_cls: 96.8750 (97.2656)  time: 2.2468  data: 2.0480  max mem: 10232
Epoch: [29] Total time: 0:00:04 (2.3933 s / it)
Averaged stats: lr: 0.000406  loss_total: 0.7825 (0.7283)  loss_cls: 0.7825 (0.7283)  acc1_cls: 89.8438 (93.79
88)  acc5_cls: 96.8750 (97.5586)
Test:  [0/4]  eta: 0:00:12  loss: 2.0180 (2.0180)  acc1_cls: 46.8750 (46.8750)  acc5_cls: 77.3438 (77.3438)  t
ime: 3.2192  data: 3.1655  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.0180 (2.0925)  acc1_cls: 41.4062 (44.4915)  acc5_cls: 74.2188 (77.3305)  t
ime: 0.9286  data: 0.8812  max mem: 10232
Test: Total time: 0:00:03 (0.9759 s / it)
* Batch-avg:             Cls Acc1: 44.492,                Cls Acc5: 77.331,                loss 2.093
Max acc1_cls: 44.49%
Epoch: [30]  [0/2]  eta: 0:00:08  lr: 0.000376  loss_total: 0.6686 (0.6686)  loss_cls: 0.6686 (0.6686)  acc1_c
ls: 96.0938 (96.0938)  acc5_cls: 100.0000 (100.0000)  time: 4.4391  data: 4.2479  max mem: 10232
Epoch: [30]  [1/2]  eta: 0:00:02  lr: 0.000376  loss_total: 0.6686 (0.7320)  loss_cls: 0.6686 (0.7320)  acc1_c
ls: 92.9688 (94.5312)  acc5_cls: 100.0000 (100.0000)  time: 2.3374  data: 2.1240  max mem: 10232
Epoch: [30] Total time: 0:00:04 (2.4766 s / it)
Averaged stats: lr: 0.000376  loss_total: 0.6686 (0.7214)  loss_cls: 0.6686 (0.7214)  acc1_cls: 92.9688 (93.94
53)  acc5_cls: 100.0000 (98.3887)
Test:  [0/4]  eta: 0:00:13  loss: 2.0071 (2.0071)  acc1_cls: 50.0000 (50.0000)  acc5_cls: 75.7812 (75.7812)  t
ime: 3.2922  data: 3.2363  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 2.0071 (2.0021)  acc1_cls: 47.6562 (47.2458)  acc5_cls: 75.7812 (77.7542)  t
ime: 0.8895  data: 0.8385  max mem: 10232
Test: Total time: 0:00:03 (0.9660 s / it)
* Batch-avg:             Cls Acc1: 47.246,                Cls Acc5: 77.754,                loss 2.002
Max acc1_cls: 47.25%
Epoch: [31]  [0/2]  eta: 0:00:08  lr: 0.000345  loss_total: 0.6194 (0.6194)  loss_cls: 0.6194 (0.6194)  acc1_c
ls: 92.9688 (92.9688)  acc5_cls: 97.6562 (97.6562)  time: 4.4325  data: 4.2387  max mem: 10232
Epoch: [31]  [1/2]  eta: 0:00:02  lr: 0.000345  loss_total: 0.5969 (0.6082)  loss_cls: 0.5969 (0.6082)  acc1_c
ls: 92.9688 (93.7500)  acc5_cls: 97.6562 (98.8281)  time: 2.3386  data: 2.1194  max mem: 10232
Epoch: [31] Total time: 0:00:05 (2.5039 s / it)
Averaged stats: lr: 0.000345  loss_total: 0.5969 (0.6577)  loss_cls: 0.5969 (0.6577)  acc1_cls: 92.9688 (94.04
30)  acc5_cls: 97.6562 (98.2910)
Test:  [0/4]  eta: 0:00:12  loss: 1.9119 (1.9119)  acc1_cls: 56.2500 (56.2500)  acc5_cls: 79.6875 (79.6875)  t
ime: 3.2116  data: 3.1556  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.9119 (1.9232)  acc1_cls: 52.3438 (51.6949)  acc5_cls: 78.9062 (80.7203)  t
ime: 0.9248  data: 0.8757  max mem: 10232
Test: Total time: 0:00:03 (0.9774 s / it)
* Batch-avg:             Cls Acc1: 51.695,                Cls Acc5: 80.720,                loss 1.923
Max acc1_cls: 51.69%
Epoch: [32]  [0/2]  eta: 0:00:08  lr: 0.000316  loss_total: 0.6363 (0.6363)  loss_cls: 0.6363 (0.6363)  acc1_c
ls: 93.7500 (93.7500)  acc5_cls: 100.0000 (100.0000)  time: 4.3475  data: 4.1536  max mem: 10232
Epoch: [32]  [1/2]  eta: 0:00:02  lr: 0.000316  loss_total: 0.6363 (0.6448)  loss_cls: 0.6363 (0.6448)  acc1_c
ls: 93.7500 (94.5312)  acc5_cls: 98.4375 (99.2188)  time: 2.2944  data: 2.0768  max mem: 10232
Epoch: [32] Total time: 0:00:04 (2.4449 s / it)
Averaged stats: lr: 0.000316  loss_total: 0.6363 (0.6350)  loss_cls: 0.6363 (0.6350)  acc1_cls: 93.7500 (94.92
19)  acc5_cls: 98.4375 (98.5352)
Test:  [0/4]  eta: 0:00:14  loss: 1.8149 (1.8149)  acc1_cls: 60.9375 (60.9375)  acc5_cls: 82.0312 (82.0312)  t
ime: 3.5536  data: 3.5000  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.8149 (1.8478)  acc1_cls: 58.5938 (56.7797)  acc5_cls: 79.5455 (81.3559)  t
ime: 0.9453  data: 0.8751  max mem: 10232
Test: Total time: 0:00:04 (1.0344 s / it)
* Batch-avg:             Cls Acc1: 56.780,                Cls Acc5: 81.356,                loss 1.848
Max acc1_cls: 56.78%
Epoch: [33]  [0/2]  eta: 0:00:09  lr: 0.000287  loss_total: 0.6263 (0.6263)  loss_cls: 0.6263 (0.6263)  acc1_c
ls: 93.7500 (93.7500)  acc5_cls: 97.6562 (97.6562)  time: 4.6706  data: 4.4753  max mem: 10232
Epoch: [33]  [1/2]  eta: 0:00:02  lr: 0.000287  loss_total: 0.6263 (0.6415)  loss_cls: 0.6263 (0.6415)  acc1_c
ls: 92.9688 (93.3594)  acc5_cls: 97.6562 (98.0469)  time: 2.4512  data: 2.2377  max mem: 10232
Epoch: [33] Total time: 0:00:05 (2.5945 s / it)
Averaged stats: lr: 0.000287  loss_total: 0.6263 (0.6205)  loss_cls: 0.6263 (0.6205)  acc1_cls: 92.9688 (94.58
01)  acc5_cls: 97.6562 (98.5840)
Test:  [0/4]  eta: 0:00:13  loss: 1.7657 (1.7657)  acc1_cls: 64.0625 (64.0625)  acc5_cls: 79.6875 (79.6875)  t
ime: 3.4309  data: 3.3778  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.7657 (1.7850)  acc1_cls: 61.7188 (60.5932)  acc5_cls: 79.6875 (81.5678)  t
ime: 0.9144  data: 0.8445  max mem: 10232
Test: Total time: 0:00:04 (1.0092 s / it)
* Batch-avg:             Cls Acc1: 60.593,                Cls Acc5: 81.568,                loss 1.785
Max acc1_cls: 60.59%
Epoch: [34]  [0/2]  eta: 0:00:08  lr: 0.000259  loss_total: 0.6379 (0.6379)  loss_cls: 0.6379 (0.6379)  acc1_c
ls: 93.7500 (93.7500)  acc5_cls: 98.4375 (98.4375)  time: 4.3823  data: 4.1756  max mem: 10232
Epoch: [34]  [1/2]  eta: 0:00:02  lr: 0.000259  loss_total: 0.5653 (0.6016)  loss_cls: 0.5653 (0.6016)  acc1_c
ls: 93.7500 (94.5312)  acc5_cls: 98.4375 (98.8281)  time: 2.3062  data: 2.0879  max mem: 10232
Epoch: [34] Total time: 0:00:04 (2.4557 s / it)
Averaged stats: lr: 0.000259  loss_total: 0.5653 (0.6056)  loss_cls: 0.5653 (0.6056)  acc1_cls: 93.7500 (95.21
48)  acc5_cls: 98.4375 (98.5352)
Test:  [0/4]  eta: 0:00:12  loss: 1.7221 (1.7221)  acc1_cls: 67.9688 (67.9688)  acc5_cls: 82.0312 (82.0312)  t
ime: 3.1463  data: 3.0913  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.7221 (1.7381)  acc1_cls: 63.2812 (63.3475)  acc5_cls: 82.0312 (82.8390)  t
ime: 0.8722  data: 0.8166  max mem: 10232
Test: Total time: 0:00:03 (0.9373 s / it)
* Batch-avg:             Cls Acc1: 63.347,                Cls Acc5: 82.839,                loss 1.738
Max acc1_cls: 63.35%
Epoch: [35]  [0/2]  eta: 0:00:08  lr: 0.000232  loss_total: 0.7197 (0.7197)  loss_cls: 0.7197 (0.7197)  acc1_c
ls: 92.1875 (92.1875)  acc5_cls: 95.3125 (95.3125)  time: 4.2244  data: 4.0310  max mem: 10232
Epoch: [35]  [1/2]  eta: 0:00:02  lr: 0.000232  loss_total: 0.6155 (0.6676)  loss_cls: 0.6155 (0.6676)  acc1_c
ls: 92.1875 (93.3594)  acc5_cls: 95.3125 (96.4844)  time: 2.2505  data: 2.0555  max mem: 10232
Epoch: [35] Total time: 0:00:04 (2.4008 s / it)
Averaged stats: lr: 0.000232  loss_total: 0.6155 (0.5709)  loss_cls: 0.6155 (0.5709)  acc1_cls: 92.1875 (95.89
84)  acc5_cls: 95.3125 (98.6328)
Test:  [0/4]  eta: 0:00:14  loss: 1.6707 (1.6707)  acc1_cls: 70.3125 (70.3125)  acc5_cls: 84.3750 (84.3750)  t
ime: 3.5182  data: 3.4636  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.6707 (1.6717)  acc1_cls: 64.8438 (65.8898)  acc5_cls: 84.3750 (84.3220)  t
ime: 0.9347  data: 0.8659  max mem: 10232
Test: Total time: 0:00:04 (1.0114 s / it)
* Batch-avg:             Cls Acc1: 65.890,                Cls Acc5: 84.322,                loss 1.672
Max acc1_cls: 65.89%
Epoch: [36]  [0/2]  eta: 0:00:09  lr: 0.000206  loss_total: 0.5039 (0.5039)  loss_cls: 0.5039 (0.5039)  acc1_c
ls: 96.0938 (96.0938)  acc5_cls: 98.4375 (98.4375)  time: 4.5641  data: 4.3765  max mem: 10232
Epoch: [36]  [1/2]  eta: 0:00:02  lr: 0.000206  loss_total: 0.5039 (0.5299)  loss_cls: 0.5039 (0.5299)  acc1_c
ls: 96.0938 (96.8750)  acc5_cls: 98.4375 (98.4375)  time: 2.3986  data: 2.1883  max mem: 10232
Epoch: [36] Total time: 0:00:05 (2.5555 s / it)
Averaged stats: lr: 0.000206  loss_total: 0.5039 (0.5496)  loss_cls: 0.5039 (0.5496)  acc1_cls: 96.0938 (96.38
67)  acc5_cls: 98.4375 (98.9746)
Test:  [0/4]  eta: 0:00:12  loss: 1.6467 (1.6467)  acc1_cls: 72.6562 (72.6562)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.2325  data: 3.1775  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.6467 (1.6311)  acc1_cls: 68.1818 (69.7034)  acc5_cls: 85.1562 (84.5339)  t
ime: 0.8931  data: 0.8450  max mem: 10232
Test: Total time: 0:00:03 (0.9633 s / it)
* Batch-avg:             Cls Acc1: 69.703,                Cls Acc5: 84.534,                loss 1.631
Max acc1_cls: 69.70%
Epoch: [37]  [0/2]  eta: 0:00:08  lr: 0.000181  loss_total: 0.6087 (0.6087)  loss_cls: 0.6087 (0.6087)  acc1_c
ls: 92.9688 (92.9688)  acc5_cls: 99.2188 (99.2188)  time: 4.3313  data: 4.1160  max mem: 10232
Epoch: [37]  [1/2]  eta: 0:00:02  lr: 0.000181  loss_total: 0.5739 (0.5913)  loss_cls: 0.5739 (0.5913)  acc1_c
ls: 92.9688 (93.3594)  acc5_cls: 99.2188 (99.2188)  time: 2.2760  data: 2.0580  max mem: 10232
Epoch: [37] Total time: 0:00:04 (2.4259 s / it)
Averaged stats: lr: 0.000181  loss_total: 0.5739 (0.5559)  loss_cls: 0.5739 (0.5559)  acc1_cls: 92.9688 (95.99
61)  acc5_cls: 99.2188 (99.1211)
Test:  [0/4]  eta: 0:00:13  loss: 1.6209 (1.6209)  acc1_cls: 71.8750 (71.8750)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.2610  data: 3.2073  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.6209 (1.5973)  acc1_cls: 71.8750 (72.2458)  acc5_cls: 85.1562 (85.1695)  t
ime: 0.8675  data: 0.8052  max mem: 10232
Test: Total time: 0:00:03 (0.9640 s / it)
* Batch-avg:             Cls Acc1: 72.246,                Cls Acc5: 85.169,                loss 1.597
Max acc1_cls: 72.25%
Epoch: [38]  [0/2]  eta: 0:00:08  lr: 0.000158  loss_total: 0.4963 (0.4963)  loss_cls: 0.4963 (0.4963)  acc1_c
ls: 96.8750 (96.8750)  acc5_cls: 98.4375 (98.4375)  time: 4.3934  data: 4.1811  max mem: 10232
Epoch: [38]  [1/2]  eta: 0:00:02  lr: 0.000158  loss_total: 0.4963 (0.5520)  loss_cls: 0.4963 (0.5520)  acc1_c
ls: 95.3125 (96.0938)  acc5_cls: 97.6562 (98.0469)  time: 2.3115  data: 2.0974  max mem: 10232
Epoch: [38] Total time: 0:00:04 (2.4775 s / it)
Averaged stats: lr: 0.000158  loss_total: 0.4963 (0.5195)  loss_cls: 0.4963 (0.5195)  acc1_cls: 95.3125 (96.28
91)  acc5_cls: 97.6562 (99.0234)
Test:  [0/4]  eta: 0:00:14  loss: 1.6008 (1.6008)  acc1_cls: 71.8750 (71.8750)  acc5_cls: 83.5938 (83.5938)  t
ime: 3.5054  data: 3.4507  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.6008 (1.5597)  acc1_cls: 71.8750 (73.7288)  acc5_cls: 83.5938 (84.1102)  t
ime: 0.9335  data: 0.8627  max mem: 10232
Test: Total time: 0:00:04 (1.0193 s / it)
* Batch-avg:             Cls Acc1: 73.729,                Cls Acc5: 84.110,                loss 1.560
Max acc1_cls: 73.73%
Epoch: [39]  [0/2]  eta: 0:00:08  lr: 0.000136  loss_total: 0.5276 (0.5276)  loss_cls: 0.5276 (0.5276)  acc1_c
ls: 96.8750 (96.8750)  acc5_cls: 100.0000 (100.0000)  time: 4.2749  data: 4.0624  max mem: 10232
Epoch: [39]  [1/2]  eta: 0:00:02  lr: 0.000136  loss_total: 0.5276 (0.5431)  loss_cls: 0.5276 (0.5431)  acc1_c
ls: 96.0938 (96.4844)  acc5_cls: 99.2188 (99.6094)  time: 2.2541  data: 2.0313  max mem: 10232
Epoch: [39] Total time: 0:00:04 (2.4090 s / it)
Averaged stats: lr: 0.000136  loss_total: 0.5276 (0.5135)  loss_cls: 0.5276 (0.5135)  acc1_cls: 96.0938 (96.09
38)  acc5_cls: 99.2188 (99.4141)
Test:  [0/4]  eta: 0:00:12  loss: 1.5850 (1.5850)  acc1_cls: 71.8750 (71.8750)  acc5_cls: 84.3750 (84.3750)  t
ime: 3.1555  data: 3.0997  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.5850 (1.5380)  acc1_cls: 71.8750 (74.3644)  acc5_cls: 84.3750 (84.3220)  t
ime: 0.9367  data: 0.8873  max mem: 10232
Test: Total time: 0:00:03 (0.9820 s / it)
* Batch-avg:             Cls Acc1: 74.364,                Cls Acc5: 84.322,                loss 1.538
Max acc1_cls: 74.36%
Epoch: [40]  [0/2]  eta: 0:00:08  lr: 0.000115  loss_total: 0.4737 (0.4737)  loss_cls: 0.4737 (0.4737)  acc1_c
ls: 97.6562 (97.6562)  acc5_cls: 99.2188 (99.2188)  time: 4.2594  data: 4.0654  max mem: 10232
Epoch: [40]  [1/2]  eta: 0:00:02  lr: 0.000115  loss_total: 0.4737 (0.5241)  loss_cls: 0.4737 (0.5241)  acc1_c
ls: 93.7500 (95.7031)  acc5_cls: 99.2188 (99.2188)  time: 2.3015  data: 2.1033  max mem: 10232
Epoch: [40] Total time: 0:00:04 (2.4649 s / it)
Averaged stats: lr: 0.000115  loss_total: 0.4737 (0.4965)  loss_cls: 0.4737 (0.4965)  acc1_cls: 93.7500 (96.58
20)  acc5_cls: 99.2188 (99.0234)
Test:  [0/4]  eta: 0:00:14  loss: 1.5512 (1.5512)  acc1_cls: 72.6562 (72.6562)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.6657  data: 3.6106  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.5512 (1.5184)  acc1_cls: 72.6562 (75.0000)  acc5_cls: 85.1562 (84.3220)  t
ime: 0.9718  data: 0.9027  max mem: 10232
Test: Total time: 0:00:04 (1.0818 s / it)
* Batch-avg:             Cls Acc1: 75.000,                Cls Acc5: 84.322,                loss 1.518
Max acc1_cls: 75.00%
Epoch: [41]  [0/2]  eta: 0:00:09  lr: 0.000096  loss_total: 0.4950 (0.4950)  loss_cls: 0.4950 (0.4950)  acc1_c
ls: 96.0938 (96.0938)  acc5_cls: 100.0000 (100.0000)  time: 4.9595  data: 4.7677  max mem: 10232
Epoch: [41]  [1/2]  eta: 0:00:02  lr: 0.000096  loss_total: 0.4495 (0.4722)  loss_cls: 0.4495 (0.4722)  acc1_c
ls: 95.3125 (95.7031)  acc5_cls: 99.2188 (99.6094)  time: 2.5982  data: 2.3839  max mem: 10232
Epoch: [41] Total time: 0:00:05 (2.7540 s / it)
Averaged stats: lr: 0.000096  loss_total: 0.4495 (0.4919)  loss_cls: 0.4495 (0.4919)  acc1_cls: 95.3125 (96.48
44)  acc5_cls: 99.2188 (99.4141)
Test:  [0/4]  eta: 0:00:13  loss: 1.5049 (1.5049)  acc1_cls: 73.4375 (73.4375)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.4178  data: 3.3624  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.5049 (1.5013)  acc1_cls: 72.7273 (74.3644)  acc5_cls: 85.1562 (84.5339)  t
ime: 0.9691  data: 0.9215  max mem: 10232
Test: Total time: 0:00:04 (1.0256 s / it)
* Batch-avg:             Cls Acc1: 74.364,                Cls Acc5: 84.534,                loss 1.501
Max acc1_cls: 75.00%
Epoch: [42]  [0/2]  eta: 0:00:11  lr: 0.000078  loss_total: 0.5377 (0.5377)  loss_cls: 0.5377 (0.5377)  acc1_c
ls: 96.8750 (96.8750)  acc5_cls: 99.2188 (99.2188)  time: 5.6035  data: 5.0326  max mem: 10232
Epoch: [42]  [1/2]  eta: 0:00:02  lr: 0.000078  loss_total: 0.4483 (0.4930)  loss_cls: 0.4483 (0.4930)  acc1_c
ls: 96.8750 (97.2656)  acc5_cls: 99.2188 (99.6094)  time: 2.9180  data: 2.5164  max mem: 10232
Epoch: [42] Total time: 0:00:06 (3.0384 s / it)
Averaged stats: lr: 0.000078  loss_total: 0.4483 (0.5185)  loss_cls: 0.4483 (0.5185)  acc1_cls: 96.8750 (96.48
44)  acc5_cls: 99.2188 (98.8281)
Test:  [0/4]  eta: 0:00:14  loss: 1.4808 (1.4808)  acc1_cls: 74.2188 (74.2188)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.5626  data: 3.5082  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4808 (1.4870)  acc1_cls: 72.7273 (74.5763)  acc5_cls: 85.1562 (85.3814)  t
ime: 0.9472  data: 0.8771  max mem: 10232
Test: Total time: 0:00:04 (1.0506 s / it)
* Batch-avg:             Cls Acc1: 74.576,                Cls Acc5: 85.381,                loss 1.487
Max acc1_cls: 75.00%
Epoch: [43]  [0/2]  eta: 0:00:10  lr: 0.000062  loss_total: 0.4102 (0.4102)  loss_cls: 0.4102 (0.4102)  acc1_c
ls: 97.6562 (97.6562)  acc5_cls: 100.0000 (100.0000)  time: 5.3687  data: 4.6496  max mem: 10232
Epoch: [43]  [1/2]  eta: 0:00:02  lr: 0.000062  loss_total: 0.4102 (0.4543)  loss_cls: 0.4102 (0.4543)  acc1_c
ls: 97.6562 (97.6562)  acc5_cls: 99.2188 (99.6094)  time: 2.8402  data: 2.3248  max mem: 10232
Epoch: [43] Total time: 0:00:05 (2.9840 s / it)
Averaged stats: lr: 0.000062  loss_total: 0.4102 (0.4613)  loss_cls: 0.4102 (0.4613)  acc1_cls: 97.6562 (97.21
68)  acc5_cls: 99.2188 (99.4141)
Test:  [0/4]  eta: 0:00:13  loss: 1.4626 (1.4626)  acc1_cls: 74.2188 (74.2188)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.2610  data: 3.2061  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4626 (1.4754)  acc1_cls: 72.7273 (74.5763)  acc5_cls: 85.1562 (85.5932)  t
ime: 0.9641  data: 0.9108  max mem: 10232
Test: Total time: 0:00:04 (1.0146 s / it)
* Batch-avg:             Cls Acc1: 74.576,                Cls Acc5: 85.593,                loss 1.475
Max acc1_cls: 75.00%
Epoch: [44]  [0/2]  eta: 0:00:11  lr: 0.000048  loss_total: 0.5296 (0.5296)  loss_cls: 0.5296 (0.5296)  acc1_c
ls: 96.0938 (96.0938)  acc5_cls: 99.2188 (99.2188)  time: 5.5165  data: 4.8454  max mem: 10232
Epoch: [44]  [1/2]  eta: 0:00:02  lr: 0.000048  loss_total: 0.4666 (0.4981)  loss_cls: 0.4666 (0.4981)  acc1_c
ls: 96.0938 (97.2656)  acc5_cls: 99.2188 (99.6094)  time: 2.8747  data: 2.4227  max mem: 10232
Epoch: [44] Total time: 0:00:06 (3.0235 s / it)
Averaged stats: lr: 0.000048  loss_total: 0.4666 (0.5068)  loss_cls: 0.4666 (0.5068)  acc1_cls: 96.0938 (96.04
49)  acc5_cls: 99.2188 (99.1699)
Test:  [0/4]  eta: 0:00:13  loss: 1.4388 (1.4388)  acc1_cls: 74.2188 (74.2188)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.4887  data: 3.4339  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4388 (1.4591)  acc1_cls: 74.2188 (75.4237)  acc5_cls: 85.1562 (85.8051)  t
ime: 0.9600  data: 0.9111  max mem: 10232
Test: Total time: 0:00:04 (1.0260 s / it)
* Batch-avg:             Cls Acc1: 75.424,                Cls Acc5: 85.805,                loss 1.459
Max acc1_cls: 75.42%
Epoch: [45]  [0/2]  eta: 0:00:09  lr: 0.000035  loss_total: 0.5447 (0.5447)  loss_cls: 0.5447 (0.5447)  acc1_c
ls: 93.7500 (93.7500)  acc5_cls: 98.4375 (98.4375)  time: 4.6268  data: 4.4386  max mem: 10232
Epoch: [45]  [1/2]  eta: 0:00:02  lr: 0.000035  loss_total: 0.5223 (0.5335)  loss_cls: 0.5223 (0.5335)  acc1_c
ls: 93.7500 (94.5312)  acc5_cls: 98.4375 (98.8281)  time: 2.5389  data: 2.3438  max mem: 10232
Epoch: [45] Total time: 0:00:05 (2.6728 s / it)
Averaged stats: lr: 0.000035  loss_total: 0.5223 (0.4996)  loss_cls: 0.5223 (0.4996)  acc1_cls: 93.7500 (96.24
02)  acc5_cls: 98.4375 (99.0723)
Test:  [0/4]  eta: 0:00:13  loss: 1.4184 (1.4184)  acc1_cls: 75.7812 (75.7812)  acc5_cls: 84.3750 (84.3750)  t
ime: 3.4451  data: 3.3891  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4184 (1.4445)  acc1_cls: 75.7812 (75.8475)  acc5_cls: 84.3750 (86.0169)  t
ime: 0.9179  data: 0.8473  max mem: 10232
Test: Total time: 0:00:04 (1.0273 s / it)
* Batch-avg:             Cls Acc1: 75.847,                Cls Acc5: 86.017,                loss 1.445
Max acc1_cls: 75.85%
Epoch: [46]  [0/2]  eta: 0:00:12  lr: 0.000024  loss_total: 0.5009 (0.5009)  loss_cls: 0.5009 (0.5009)  acc1_c
ls: 94.5312 (94.5312)  acc5_cls: 98.4375 (98.4375)  time: 6.4569  data: 6.2688  max mem: 10232
Epoch: [46]  [1/2]  eta: 0:00:03  lr: 0.000024  loss_total: 0.4863 (0.4936)  loss_cls: 0.4863 (0.4936)  acc1_c
ls: 94.5312 (95.3125)  acc5_cls: 98.4375 (98.8281)  time: 3.3449  data: 3.1345  max mem: 10232
Epoch: [46] Total time: 0:00:07 (3.5056 s / it)
Averaged stats: lr: 0.000024  loss_total: 0.4863 (0.4663)  loss_cls: 0.4863 (0.4663)  acc1_cls: 94.5312 (97.26
56)  acc5_cls: 98.4375 (99.5605)
Test:  [0/4]  eta: 0:00:14  loss: 1.4148 (1.4148)  acc1_cls: 75.7812 (75.7812)  acc5_cls: 84.3750 (84.3750)  t
ime: 3.5982  data: 3.5452  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4148 (1.4317)  acc1_cls: 75.7812 (76.0593)  acc5_cls: 84.3750 (85.3814)  t
ime: 0.9551  data: 0.8863  max mem: 10232
Test: Total time: 0:00:04 (1.0476 s / it)
* Batch-avg:             Cls Acc1: 76.059,                Cls Acc5: 85.381,                loss 1.432
Max acc1_cls: 76.06%
Epoch: [47]  [0/2]  eta: 0:00:12  lr: 0.000016  loss_total: 0.4548 (0.4548)  loss_cls: 0.4548 (0.4548)  acc1_c
ls: 100.0000 (100.0000)  acc5_cls: 100.0000 (100.0000)  time: 6.1215  data: 5.9292  max mem: 10232
Epoch: [47]  [1/2]  eta: 0:00:03  lr: 0.000016  loss_total: 0.4308 (0.4428)  loss_cls: 0.4308 (0.4428)  acc1_c
ls: 97.6562 (98.8281)  acc5_cls: 100.0000 (100.0000)  time: 3.1778  data: 2.9647  max mem: 10232
Epoch: [47] Total time: 0:00:06 (3.3441 s / it)
Averaged stats: lr: 0.000016  loss_total: 0.4308 (0.4771)  loss_cls: 0.4308 (0.4771)  acc1_cls: 97.6562 (96.67
97)  acc5_cls: 100.0000 (99.6582)
Test:  [0/4]  eta: 0:00:13  loss: 1.4191 (1.4191)  acc1_cls: 75.7812 (75.7812)  acc5_cls: 84.3750 (84.3750)  t
ime: 3.4639  data: 3.4104  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4191 (1.4200)  acc1_cls: 75.7812 (76.2712)  acc5_cls: 84.3750 (85.5932)  t
ime: 0.9219  data: 0.8526  max mem: 10232
Test: Total time: 0:00:04 (1.0181 s / it)
* Batch-avg:             Cls Acc1: 76.271,                Cls Acc5: 85.593,                loss 1.420
Max acc1_cls: 76.27%
Epoch: [48]  [0/2]  eta: 0:00:14  lr: 0.000009  loss_total: 0.4158 (0.4158)  loss_cls: 0.4158 (0.4158)  acc1_c
ls: 96.8750 (96.8750)  acc5_cls: 100.0000 (100.0000)  time: 7.1279  data: 6.9324  max mem: 10232
Epoch: [48]  [1/2]  eta: 0:00:03  lr: 0.000009  loss_total: 0.4158 (0.4612)  loss_cls: 0.4158 (0.4612)  acc1_c
ls: 96.0938 (96.4844)  acc5_cls: 100.0000 (100.0000)  time: 3.6815  data: 3.4662  max mem: 10232
Epoch: [48] Total time: 0:00:07 (3.8354 s / it)
Averaged stats: lr: 0.000009  loss_total: 0.4158 (0.4740)  loss_cls: 0.4158 (0.4740)  acc1_cls: 96.0938 (96.72
85)  acc5_cls: 100.0000 (99.4141)
Test:  [0/4]  eta: 0:00:12  loss: 1.4141 (1.4141)  acc1_cls: 75.7812 (75.7812)  acc5_cls: 84.3750 (84.3750)  t
ime: 3.2153  data: 3.1621  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.4141 (1.4062)  acc1_cls: 75.7812 (76.6949)  acc5_cls: 84.3750 (85.8051)  t
ime: 0.8583  data: 0.7991  max mem: 10232
Test: Total time: 0:00:03 (0.9433 s / it)
* Batch-avg:             Cls Acc1: 76.695,                Cls Acc5: 85.805,                loss 1.406
Max acc1_cls: 76.69%
Epoch: [49]  [0/2]  eta: 0:00:13  lr: 0.000004  loss_total: 0.4546 (0.4546)  loss_cls: 0.4546 (0.4546)  acc1_c
ls: 96.8750 (96.8750)  acc5_cls: 99.2188 (99.2188)  time: 6.9337  data: 6.7205  max mem: 10232
Epoch: [49]  [1/2]  eta: 0:00:03  lr: 0.000004  loss_total: 0.4546 (0.4710)  loss_cls: 0.4546 (0.4710)  acc1_c
ls: 94.5312 (95.7031)  acc5_cls: 97.6562 (98.4375)  time: 3.5772  data: 3.3661  max mem: 10232
Epoch: [49] Total time: 0:00:07 (3.7388 s / it)
Averaged stats: lr: 0.000004  loss_total: 0.4546 (0.4678)  loss_cls: 0.4546 (0.4678)  acc1_cls: 94.5312 (96.38
67)  acc5_cls: 97.6562 (99.0234)
Test:  [0/4]  eta: 0:00:14  loss: 1.3984 (1.3984)  acc1_cls: 75.7812 (75.7812)  acc5_cls: 85.1562 (85.1562)  t
ime: 3.5639  data: 3.5103  max mem: 10232
Test:  [3/4]  eta: 0:00:00  loss: 1.3984 (1.3966)  acc1_cls: 75.7812 (76.6949)  acc5_cls: 85.1562 (86.4407)  t
ime: 0.9466  data: 0.8776  max mem: 10232
Test: Total time: 0:00:04 (1.0518 s / it)
* Batch-avg:             Cls Acc1: 76.695,                Cls Acc5: 86.441,                loss 1.397
Max acc1_cls: 76.69%
Training time 0:24:59
wandb: Waiting for W&B process to finish... (success).
wandb:  View run in1k_jigsaw_small_patch56_336_e30_c1000frcl50 at: https://wandb.ai/doem97/Puzzle/runs/6wife
ril
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)batch_size: 128
epochs: 50
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_small_patch56_336
input_size: 336
permcls: 1000
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-08
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000/best_checkpoint.pth
attn_only: False
data_path: /workspace/data/imagenet/ILSVRC/Data/CLS-LOC
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000frcl50
log_dir: ./logs/in1k_jigsaw_small_patch56_336_e30_c1000frcl50
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 1
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 4.073, acc1_cls: 1.059, acc5_cls: 9.322
