batch_size: 768
epochs: 50
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-05
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./data/checkpoints/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/cs
data_set: CS
nb_classes: 50
inat_category: name
output_dir: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e50_1e-3_1024
log_dir: ./logs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e50_1e-3_1024
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 1
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 83.687, acc1_cls: 1.907, acc5_cls: 11.017
{"train_lr": 0.001, "train_loss_total": 4.227752049763997, "train_loss_cls": 4.227752049763997, "train_acc1_cls": 5.5121528307596845, "train_acc5_cls": 15.711805661519369, "epoch": 0, "n_parameters": 613877740}
Evaluation on epoch 1: loss: 26.957, acc1_cls: 2.119, acc5_cls: 11.017
{"train_lr": 0.001, "train_loss_total": 4.04827078183492, "train_loss_cls": 4.04827078183492, "train_acc1_cls": 9.20138931274414, "train_acc5_cls": 25.30382029215495, "epoch": 1, "n_parameters": 613877740}
Evaluation on epoch 2: loss: 14.935, acc1_cls: 2.542, acc5_cls: 12.924
{"train_lr": 0.0009990232305719944, "train_loss_total": 4.078160762786865, "train_loss_cls": 4.078160762786865, "train_acc1_cls": 7.465277989705403, "train_acc5_cls": 25.173611958821613, "epoch": 2, "n_parameters": 613877740}
Evaluation on epoch 3: loss: 18.593, acc1_cls: 4.237, acc5_cls: 11.017
{"train_lr": 0.0009960967771506667, "train_loss_total": 4.026298761367798, "train_loss_cls": 4.026298761367798, "train_acc1_cls": 8.854166984558105, "train_acc5_cls": 29.253472646077473, "epoch": 3, "n_parameters": 613877740}
Evaluation on epoch 4: loss: 18.390, acc1_cls: 2.119, acc5_cls: 13.136
{"train_lr": 0.000991232189110701, "train_loss_total": 4.009344259897868, "train_loss_cls": 4.009344259897868, "train_acc1_cls": 9.939236323038736, "train_acc5_cls": 28.689236323038738, "epoch": 4, "n_parameters": 613877740}
Evaluation on epoch 5: loss: 20.338, acc1_cls: 1.695, acc5_cls: 11.229
{"train_lr": 0.0009844486647586723, "train_loss_total": 3.974684794743856, "train_loss_cls": 3.974684794743856, "train_acc1_cls": 11.197916984558105, "train_acc5_cls": 30.46875063578288, "epoch": 5, "n_parameters": 613877740}
Evaluation on epoch 6: loss: 11.072, acc1_cls: 2.119, acc5_cls: 12.924
{"train_lr": 0.0009757729755661011, "train_loss_total": 3.895174582799276, "train_loss_cls": 3.895174582799276, "train_acc1_cls": 12.977430979410807, "train_acc5_cls": 30.59895896911621, "epoch": 6, "n_parameters": 613877740}
Evaluation on epoch 7: loss: 7.600, acc1_cls: 3.390, acc5_cls: 11.864
{"train_lr": 0.0009652393605146843, "train_loss_total": 3.7692007223765054, "train_loss_cls": 3.7692007223765054, "train_acc1_cls": 13.845486640930176, "train_acc5_cls": 33.723959604899086, "epoch": 7, "n_parameters": 613877740}
Evaluation on epoch 8: loss: 6.315, acc1_cls: 5.085, acc5_cls: 15.254
{"train_lr": 0.0009528893909706797, "train_loss_total": 3.49274476369222, "train_loss_cls": 3.49274476369222, "train_acc1_cls": 20.65972328186035, "train_acc5_cls": 40.71180725097656, "epoch": 8, "n_parameters": 613877740}
Evaluation on epoch 9: loss: 5.228, acc1_cls: 5.720, acc5_cls: 16.737
{"train_lr": 0.0009387718066217124, "train_loss_total": 3.2423837184906006, "train_loss_cls": 3.2423837184906006, "train_acc1_cls": 26.996527989705402, "train_acc5_cls": 47.52604293823242, "epoch": 9, "n_parameters": 613877740}
Evaluation on epoch 10: loss: 5.074, acc1_cls: 7.839, acc5_cls: 19.280
{"train_lr": 0.0009229423231234975, "train_loss_total": 3.0696871280670166, "train_loss_cls": 3.0696871280670166, "train_acc1_cls": 31.38020896911621, "train_acc5_cls": 52.77777862548828, "epoch": 10, "n_parameters": 613877740}
Evaluation on epoch 11: loss: 5.173, acc1_cls: 7.415, acc5_cls: 21.822
{"train_lr": 0.000905463412215599, "train_loss_total": 2.877868970235189, "train_loss_cls": 2.877868970235189, "train_acc1_cls": 37.93402862548828, "train_acc5_cls": 59.852430979410805, "epoch": 11, "n_parameters": 613877740}
Evaluation on epoch 12: loss: 5.051, acc1_cls: 14.195, acc5_cls: 21.186
{"train_lr": 0.0008864040551740156, "train_loss_total": 2.5833022594451904, "train_loss_cls": 2.5833022594451904, "train_acc1_cls": 45.31250127156576, "train_acc5_cls": 68.09896341959636, "epoch": 12, "n_parameters": 613877740}
Evaluation on epoch 13: loss: 4.978, acc1_cls: 13.136, acc5_cls: 21.398
{"train_lr": 0.0008658394705735988, "train_loss_total": 2.4592471917470298, "train_loss_cls": 2.4592471917470298, "train_acc1_cls": 50.694445292154946, "train_acc5_cls": 69.5746561686198, "epoch": 13, "n_parameters": 613877740}
Evaluation on epoch 14: loss: 4.780, acc1_cls: 12.500, acc5_cls: 23.729
{"train_lr": 0.0008438508174347009, "train_loss_total": 2.3144546349843345, "train_loss_cls": 2.3144546349843345, "train_acc1_cls": 54.5138905843099, "train_acc5_cls": 72.56944529215495, "epoch": 14, "n_parameters": 613877740}
Evaluation on epoch 15: loss: 4.372, acc1_cls: 17.797, acc5_cls: 30.932
{"train_lr": 0.0008205248749256015, "train_loss_total": 2.0743583838144937, "train_loss_cls": 2.0743583838144937, "train_acc1_cls": 62.36979420979818, "train_acc5_cls": 79.64409891764323, "epoch": 15, "n_parameters": 613877740}
Evaluation on epoch 16: loss: 3.970, acc1_cls: 17.161, acc5_cls: 36.017
{"train_lr": 0.0007959536998847742, "train_loss_total": 1.9451090494791667, "train_loss_cls": 1.9451090494791667, "train_acc1_cls": 64.93055979410808, "train_acc5_cls": 80.90277862548828, "epoch": 16, "n_parameters": 613877740}
Evaluation on epoch 17: loss: 3.822, acc1_cls: 15.678, acc5_cls: 40.042
{"train_lr": 0.0007702342635146033, "train_loss_total": 1.686800440152486, "train_loss_cls": 1.686800440152486, "train_acc1_cls": 72.22222646077473, "train_acc5_cls": 86.41493225097656, "epoch": 17, "n_parameters": 613877740}
Evaluation on epoch 18: loss: 3.650, acc1_cls: 18.432, acc5_cls: 40.678
{"train_lr": 0.000743468068680349, "train_loss_total": 1.5407905181248982, "train_loss_cls": 1.5407905181248982, "train_acc1_cls": 76.90972646077473, "train_acc5_cls": 88.23784891764323, "epoch": 18, "n_parameters": 613877740}
Evaluation on epoch 19: loss: 3.494, acc1_cls: 19.280, acc5_cls: 41.737
{"train_lr": 0.000715760749324711, "train_loss_total": 1.4310541947682698, "train_loss_cls": 1.4310541947682698, "train_acc1_cls": 77.30035146077473, "train_acc5_cls": 89.49652862548828, "epoch": 19, "n_parameters": 613877740}
Evaluation on epoch 20: loss: 3.315, acc1_cls: 23.305, acc5_cls: 47.881
{"train_lr": 0.0006872216535789157, "train_loss_total": 1.2950152953465779, "train_loss_cls": 1.2950152953465779, "train_acc1_cls": 80.9027811686198, "train_acc5_cls": 91.31944783528645, "epoch": 20, "n_parameters": 613877740}
Evaluation on epoch 21: loss: 3.224, acc1_cls: 22.458, acc5_cls: 50.636
{"train_lr": 0.000657963412215599, "train_loss_total": 1.1607409318288167, "train_loss_cls": 1.1607409318288167, "train_acc1_cls": 84.76562754313152, "train_acc5_cls": 92.83854420979817, "epoch": 21, "n_parameters": 613877740}
Evaluation on epoch 22: loss: 3.282, acc1_cls: 19.915, acc5_cls: 49.364
{"train_lr": 0.000628101494146603, "train_loss_total": 1.089850385983785, "train_loss_cls": 1.089850385983785, "train_acc1_cls": 84.72222391764323, "train_acc5_cls": 93.53298695882161, "epoch": 22, "n_parameters": 613877740}
Evaluation on epoch 23: loss: 3.292, acc1_cls: 17.161, acc5_cls: 52.119
{"train_lr": 0.0005977537507199338, "train_loss_total": 0.9661371906598409, "train_loss_cls": 0.9661371906598409, "train_acc1_cls": 86.32812754313152, "train_acc5_cls": 94.01041920979817, "epoch": 23, "n_parameters": 613877740}
Evaluation on epoch 24: loss: 3.169, acc1_cls: 18.644, acc5_cls: 53.178
{"train_lr": 0.0005670399506143307, "train_loss_total": 0.8916645050048828, "train_loss_cls": 0.8916645050048828, "train_acc1_cls": 87.80382283528645, "train_acc5_cls": 95.22569783528645, "epoch": 24, "n_parameters": 613877740}
Evaluation on epoch 25: loss: 3.082, acc1_cls: 18.644, acc5_cls: 56.780
{"train_lr": 0.0005360813071670102, "train_loss_total": 0.8098498582839966, "train_loss_cls": 0.8098498582839966, "train_acc1_cls": 90.32118225097656, "train_acc5_cls": 96.91840362548828, "epoch": 25, "n_parameters": 613877740}
Evaluation on epoch 26: loss: 3.017, acc1_cls: 18.008, acc5_cls: 59.958
{"train_lr": 0.000505, "train_loss_total": 0.7078826030095419, "train_loss_cls": 0.7078826030095419, "train_acc1_cls": 91.88368479410808, "train_acc5_cls": 96.78819783528645, "epoch": 26, "n_parameters": 613877740}
Evaluation on epoch 27: loss: 2.746, acc1_cls: 27.119, acc5_cls: 65.254
{"train_lr": 0.00047391869283298986, "train_loss_total": 0.623010496298472, "train_loss_cls": 0.623010496298472, "train_acc1_cls": 92.23090362548828, "train_acc5_cls": 98.00347646077473, "epoch": 27, "n_parameters": 613877740}
Evaluation on epoch 28: loss: 2.732, acc1_cls: 25.847, acc5_cls: 67.797
{"train_lr": 0.0004429600493856695, "train_loss_total": 0.5692460934321085, "train_loss_cls": 0.5692460934321085, "train_acc1_cls": 93.44618225097656, "train_acc5_cls": 98.39409891764323, "epoch": 28, "n_parameters": 613877740}
Evaluation on epoch 29: loss: 2.765, acc1_cls: 23.729, acc5_cls: 68.856
{"train_lr": 0.00041224624928006627, "train_loss_total": 0.5164054830869039, "train_loss_cls": 0.5164054830869039, "train_acc1_cls": 94.18402862548828, "train_acc5_cls": 98.39410146077473, "epoch": 29, "n_parameters": 613877740}
Evaluation on epoch 30: loss: 2.660, acc1_cls: 29.237, acc5_cls: 70.975
{"train_lr": 0.00038189850585339686, "train_loss_total": 0.4892706274986267, "train_loss_cls": 0.4892706274986267, "train_acc1_cls": 94.61805725097656, "train_acc5_cls": 98.74132283528645, "epoch": 30, "n_parameters": 613877740}
Evaluation on epoch 31: loss: 2.414, acc1_cls: 41.737, acc5_cls: 74.153
{"train_lr": 0.0003520365877844012, "train_loss_total": 0.41700730721155804, "train_loss_cls": 0.41700730721155804, "train_acc1_cls": 96.22395833333333, "train_acc5_cls": 99.2621561686198, "epoch": 31, "n_parameters": 613877740}
Evaluation on epoch 32: loss: 2.281, acc1_cls: 48.093, acc5_cls: 76.907
{"train_lr": 0.00032277834642108455, "train_loss_total": 0.39336196581522626, "train_loss_cls": 0.39336196581522626, "train_acc1_cls": 96.35416920979817, "train_acc5_cls": 98.8715311686198, "epoch": 32, "n_parameters": 613877740}
Evaluation on epoch 33: loss: 2.288, acc1_cls: 48.517, acc5_cls: 77.754
{"train_lr": 0.0002942392506752891, "train_loss_total": 0.3553202152252197, "train_loss_cls": 0.3553202152252197, "train_acc1_cls": 97.43923950195312, "train_acc5_cls": 99.2621561686198, "epoch": 33, "n_parameters": 613877740}
Evaluation on epoch 34: loss: 2.297, acc1_cls: 48.729, acc5_cls: 77.542
{"train_lr": 0.0002665319313196509, "train_loss_total": 0.3509206473827362, "train_loss_cls": 0.3509206473827362, "train_acc1_cls": 96.83159891764323, "train_acc5_cls": 99.04514058430989, "epoch": 34, "n_parameters": 613877740}
Evaluation on epoch 35: loss: 2.150, acc1_cls: 54.025, acc5_cls: 78.390
{"train_lr": 0.00023976573648539653, "train_loss_total": 0.3217788636684418, "train_loss_cls": 0.3217788636684418, "train_acc1_cls": 97.13542175292969, "train_acc5_cls": 99.21875254313152, "epoch": 35, "n_parameters": 613877740}
Evaluation on epoch 36: loss: 1.985, acc1_cls: 58.898, acc5_cls: 79.661
{"train_lr": 0.00021404630011522585, "train_loss_total": 0.29109900693098706, "train_loss_cls": 0.29109900693098706, "train_acc1_cls": 97.87326558430989, "train_acc5_cls": 99.60937754313152, "epoch": 36, "n_parameters": 613877740}
Evaluation on epoch 37: loss: 1.928, acc1_cls: 61.653, acc5_cls: 79.661
{"train_lr": 0.00018947512507439858, "train_loss_total": 0.2912798523902893, "train_loss_cls": 0.2912798523902893, "train_acc1_cls": 97.00521087646484, "train_acc5_cls": 99.60937754313152, "epoch": 37, "n_parameters": 613877740}
Evaluation on epoch 38: loss: 1.900, acc1_cls: 63.136, acc5_cls: 80.085
{"train_lr": 0.0001661491825652991, "train_loss_total": 0.28456641733646393, "train_loss_cls": 0.28456641733646393, "train_acc1_cls": 97.96007283528645, "train_acc5_cls": 99.60938008626302, "epoch": 38, "n_parameters": 613877740}
Evaluation on epoch 39: loss: 1.888, acc1_cls: 63.559, acc5_cls: 80.508
{"train_lr": 0.0001441605294264014, "train_loss_total": 0.26338137686252594, "train_loss_cls": 0.26338137686252594, "train_acc1_cls": 98.2638931274414, "train_acc5_cls": 99.73958587646484, "epoch": 39, "n_parameters": 613877740}
Evaluation on epoch 40: loss: 1.873, acc1_cls: 64.195, acc5_cls: 80.720
{"train_lr": 0.00012359594482598438, "train_loss_total": 0.25285711387793225, "train_loss_cls": 0.25285711387793225, "train_acc1_cls": 98.30729420979817, "train_acc5_cls": 99.73958587646484, "epoch": 40, "n_parameters": 613877740}
Evaluation on epoch 41: loss: 1.851, acc1_cls: 64.619, acc5_cls: 81.992
{"train_lr": 0.00010453658778440107, "train_loss_total": 0.24047917127609253, "train_loss_cls": 0.24047917127609253, "train_acc1_cls": 98.52430725097656, "train_acc5_cls": 99.78298950195312, "epoch": 41, "n_parameters": 613877740}
Evaluation on epoch 42: loss: 1.817, acc1_cls: 65.466, acc5_cls: 81.992
{"train_lr": 8.705767687650265e-05, "train_loss_total": 0.24843718111515045, "train_loss_cls": 0.24843718111515045, "train_acc1_cls": 98.52430725097656, "train_acc5_cls": 99.65277862548828, "epoch": 42, "n_parameters": 613877740}
Evaluation on epoch 43: loss: 1.776, acc1_cls: 67.161, acc5_cls: 82.415
{"train_lr": 7.122819337828752e-05, "train_loss_total": 0.21672503153483072, "train_loss_cls": 0.21672503153483072, "train_acc1_cls": 98.39409891764323, "train_acc5_cls": 99.91319529215495, "epoch": 43, "n_parameters": 613877740}
Evaluation on epoch 44: loss: 1.735, acc1_cls: 69.068, acc5_cls: 82.627
{"train_lr": 5.711060902932042e-05, "train_loss_total": 0.21808026234308878, "train_loss_cls": 0.21808026234308878, "train_acc1_cls": 98.8715311686198, "train_acc5_cls": 99.91319783528645, "epoch": 44, "n_parameters": 613877740}
Evaluation on epoch 45: loss: 1.700, acc1_cls: 69.915, acc5_cls: 82.839
{"train_lr": 4.4760639485315584e-05, "train_loss_total": 0.21855160097281137, "train_loss_cls": 0.21855160097281137, "train_acc1_cls": 98.78472391764323, "train_acc5_cls": 99.82639058430989, "epoch": 45, "n_parameters": 613877740}
Evaluation on epoch 46: loss: 1.676, acc1_cls: 70.127, acc5_cls: 82.839
{"train_lr": 3.4227024433899005e-05, "train_loss_total": 0.2291456957658132, "train_loss_cls": 0.2291456957658132, "train_acc1_cls": 98.35069783528645, "train_acc5_cls": 99.73958587646484, "epoch": 46, "n_parameters": 613877740}
Evaluation on epoch 47: loss: 1.660, acc1_cls: 70.127, acc5_cls: 83.475
{"train_lr": 2.5551335241327672e-05, "train_loss_total": 0.23278264701366425, "train_loss_cls": 0.23278264701366425, "train_acc1_cls": 98.4809061686198, "train_acc5_cls": 99.73958587646484, "epoch": 47, "n_parameters": 613877740}
Evaluation on epoch 48: loss: 1.650, acc1_cls: 70.763, acc5_cls: 83.686
{"train_lr": 1.8767810889299086e-05, "train_loss_total": 0.1978700409332911, "train_loss_cls": 0.1978700409332911, "train_acc1_cls": 99.17534891764323, "train_acc5_cls": 99.73958587646484, "epoch": 48, "n_parameters": 613877740}
Evaluation on epoch 49: loss: 1.642, acc1_cls: 70.339, acc5_cls: 83.686
{"train_lr": 1.3903222849333507e-05, "train_loss_total": 0.20228594541549683, "train_loss_cls": 0.20228594541549683, "train_acc1_cls": 98.52430979410808, "train_acc5_cls": 99.78298695882161, "epoch": 49, "n_parameters": 613877740}
